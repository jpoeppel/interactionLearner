\chapter{Concept \label{chap:concept}}

%Big picture
%General ideas how to solve goals
%Present equal concepts with theoretical pro's and cons
%What are the general ideas that we try to solve the problem with?

%TODO check possible acronyms: nearest neighbor, abstract collection!!
%TODO make sure to write things like abstract collection the same every time (ie abstract collection vs Abstract Collection) !!

Instead of using only a single regression model that is constantly updated and queried, the robot needs some sort of architecture in order to deal with the continuous information stream. This architecture needs to organize the incoming data and determine what should be learned from these experiences. Furthermore, the architecture can combine different components in order to make the best use of what it has learned. 
This chapter presents the two concepts that were developed in order to fulfill these tasks. These two concepts differentiate mainly in the way they represent the interactions that they learn about. The first concept, further described in section \ref{sec:pairInt} uses pairwise interactions two represent the objects in the environment. In the alternative approach, described in section \ref{sec:gate}, the objects are represented individually. Additionally, a gating function is introduced to distinguish when one object actually influences another. 
A special inverse model is proposed in section \ref{sec:invModel} that is tailored to the continuous interaction with the environment. %TODO more either here or in the introduction?
Before going into the description of both concepts and the inverse model, section \ref{sec:problem} summarizes the actual problem these concepts need to solve. 

%Unlike in isolated classification or regression tasks, it is not enough to employ one specialized machine learning algorithm in order to solve the given problem. Since the model is supposed to interact with its environment and update itself while experiencing new interactions, a more important complex model is required. While the chosen underlying regression and classification methods need to fulfill certain conditions and greatly influence the resulting model performance, they could easily replaced by suitable alternatives. Even more important is the architecture around them, that organizes the information coming from the environment and adapts where necessary. This chapter presents the general concepts behind the two developed models and the way the information is organized.
%
%First a more detailed specification about the problem is given in section \ref{sec:problem}. Afterwards,
%section \ref{sec:pairInt} describes the first developed concepts working solely in what is called the interaction space in this thesis. The alternative approach of modeling object states directly is described in section \ref{sec:gate}.

\section{Problem specification \label{sec:problem}}

As stated in the introduction, the goal of this thesis is to provide possible models that incrementally learn simple pushing interactions between physical objects. 
More specifically, given some known action primitive that controls the robots actuator, the models need to learn to predict the next states of all objects in the environment (forward model). 
While these action primitives are determined beforehand, the model does not necessarily know the effects of the primitives. In this case, the model needs to not only learn about the pushing interactions, but also about the forward model of its own actions.

Apart from the forward model, the robot is also supposed to be able to reach some specified target configuration (inverse model). Any object in the environment, not just the actuator, can be specified which means that the model must learn how it can influence the objects through its actuator. The target configurations will rarely be reachable within a single action primitive but the inverse model should provide actions that reduce the distance to the target configuration. Since the actuator can only influence another object by pushing it, the actuator might be required to circle around an object in order to be able to move it towards the desired configuration. 

Both of these tasks need to be learned incrementally without prior training. This requires the model to be tightly coupled to the environment. An overview about the models interaction with the environment can be seen in figure \ref{fig:overview}. The model is updated each time feedback from the environment is received, allowing better predictions.


\begin{figure}
	\centering
	\includegraphics{Overview.pdf}
	\caption{Overview of the problem. The model includes a forward model in order to make predictions given the current environment state and a certain action primitive. When given a target state the inverse model provides suitable action primitives to reach the desired state.}
	\label{fig:overview}
\end{figure}

\section{Modeling pairwise interactions \label{sec:pairInt}}

The first approach tries to find distinct subspaces in the \textit{interaction space} between two objects. In this context, the interaction space represents the space of all interactions between two objects. This includes their relative placement and movement to each other, as well as their influence, for example by pushing, on each other. Instead of modeling and learning forward and inverse models for each object separately, only the pairwise interaction space between two objects is considered.  

For every object pair an \textit{interaction state} is considered. This interaction state represents one object's state relative to the other object's state. This includes for example transforming each objects position and orientation to the local coordinate system of the reference object. %For the realization, described in section \ref{sec:pairRealization}, he actuator is not used as reference.
The predicted object states are extracted from the predicted interaction states. The way these interaction states are computed from the object states and how the object states can be extracted from the predicted interaction states, need to be provided to the model beforehand. %TODO elaborate more on this?

At each update step the current interaction states for all object pairs are computed from the information provided by the environment. The previous state, the performed action and the resulting state are collected and stored as an \textit{episode}. The general idea is to store these episodes as past knowledge similar to the approach in case based reasoning \cite{cbr}. When predicting, these episodes can be searched for the most similar one. The similarity can be determined by comparing the previous state of each episode to the given interaction state and the used action to the current action:

\begin{equation}
e^{best} = \argmin_{e^i \in E} ||e^i_{preState}-curState, e^i_{action}-curAction||_e
\label{eq:bestEpisode}
\end{equation}


$e^i$ represents the i's episode that has been stored yet. $e^i_{preState}$ means only the previous interaction state of the episode, while $e^i_{action}$ represents the used action in that episode.
The norm $||a,b||_e$ is used to allow different weighting of the features from the previous state and the action. For planning, the action difference can be replaced by the difference between the resulting state of each episode and the desired target state.

Once the most similar episode has been found, the desired information can be extracted from it. For prediction, this corresponds to the resulting state in the episode, whereas it corresponds to the action for planning. The formula above represents a nearest neighbor search on all episodes. Although such an approach can work, it quickly becomes infeasible when the number of stored episode keeps growing. Since the nearest neighbor search scales linearly with the number of stored examples it is unsuitable for lifelong learning. Furthermore, the simple nearest neighbor approach does not offer good generalization since it does not interpolate between episodes.

As mentioned above, the idea of this concept is to split the interaction space into subspaces and train local models for each of these subspaces. An overview of the proposed architecture can be seen in figure \ref{fig:PairOverview}.
All episodes corresponding to the same subspace are collected in \textit{Abstract Collections}. Each collection trains their own local forward and inverse model which is explained in section \ref{sec:ACs}.
An \textit{Abstract Collection Selector} is needed in order to choose the most appropriate abstract collection in a given situation. 

%The realization of this concept is described in section \ref{sec:pairRealization}.

\begin{figure}
	\centering
	\includegraphics{PairwiseOverview.pdf}
	\caption{Overview of the model in interaction space. The different abstract collections contain forward and inverse models of distinct subspaces of the interaction space. The selector is needed in order to select the correct submodel for prediction.}%TODO consider adding transformation to interaction state and back to object states as well?} %TODO
	\label{fig:PairOverview}
\end{figure}

\subsection{Abstract Collection \label{sec:ACs}}

The interaction space can be split in a multitude of subspaces. Ideally, one would want to split the space in subspaces with some semantic meaning, for example into \textit{no interaction}, \textit{turning} and \textit{pushing}. In this example, the no interaction subspace would correspond to the episodes where the actuator moves without influencing another object. Turning would correspond to an interaction where mainly the orientation of an object changes through the interaction. Lastly, mainly the position of an object changes in the pushing subspace. However, in order to separate the episodes like that, accurate labels are required. Such a classification is not possible without prior domain knowledge. Instead of relying on domain knowledge, this approach uses the information available to the robot from the environment: The changing features within an episode.

The clustering of episodes suggested here is based on the set of features that changed between the previous state and the resulting state while performing an action. The set $S$ of features that changed is defined as follows 
\begin{equation}
S = \{f | f \in F ~ \wedge ~ ||Pre(f)-Post(f)|| > \epsilon_{Noise}\}
\end{equation}
where $F$ denotes the set of all features, $Pre(f), Post(f)$, the value of 
feature $f$ in the initial and resulting state of the episode respectively. $\epsilon_{Noise}$ is a threshold to cancel out potential noise of the environment and should be set according to the accuracy of the used sensors.

Each different set is represented by its own abstract collection $AC_i$. The 
idea is that, while not necessarily holding semantic meaning directly, these collections correspond to different interaction scenarios. Depending on the features used, some abstract collections might even be interpreted semantically.
Consider an exemplary interaction state with two features. The first feature represents the closest distance between the two objects in the interaction state. The second feature represents the angular direction of the second object with respect to the local coordinate system of the reference object. While the model itself has no knowledge about what each feature represents, a maximum of four abstract collections can be created: No feature changes, either one of the two features changes and both change at the same time. In this example the abstract collection containing only the distance feature represents all interactions where one object moves straight towards or away from the other object. The set where nothing changes would signal a pushing interaction, considering a movement action was performed. While not all created abstract collections can be interpreted semantically, the model can create these separations without any knowledge about what is represented by the features.

Since each distinct interaction scenario results in a different set of changing features, the interaction space is split into subspaces by these collections. The resulting collections create an abstract representation for each of these interaction scenarios. 

These collections train their respective local forward and inverse models based on the episodes associated with them. Any suitable regression method can be used for these local models. The above mentioned nearest neighbor structure that works directly on the recorded episodes is just one simple example. Since the collections are independent of each other, different collections can even use different methods if desired. Furthermore, local optimizations such as feature selection could be performed in each collection. %TODO mention feature selection when it is not done/evaluated currently?

%The \gls{aitm} (see section \ref{sec:ITM}) used for the prototype implementation behaves similar to a \gls{knn}. 

\subsection{Prediction with the Abstract Collection Selector}
%TODO consider removing DT here, since it is not used anymore and was never as good as what we have now
Prediction within this architecture requires several steps. The general idea of the information flow when predicting one interaction state is visualized in figure \ref{fig:PairPrediction}. The model expects an interaction state that has been computed from the objects information provided by the environment. This interaction state is used together with the given action primitive as input for the Abstract Collection Selector. The selector needs to estimate which Abstract Collection is most likely responsible for the next interaction. In order to make this estimation, any suitable classifier, e.g. a decision tree \cite{DT}, is trained on all input-collection pairs the model experienced so far. 
%TODO maybe remove/rewrite this following passage
The total number of collections is limited to the size of the superset of $F$, although in practice, not all possibilities are likely and only those collections are considered, that are already made up of more than $\epsilon_{min}$ training examples. This threshold is used to reduce the number of outliers when training the classifier. %TODO this threshold does not exist anymore in the current implementation!!

After the most likely Abstract Collection has been selected, its forward model can be consulted for the prediction. The local model will also be queried using the interaction state together with the given action primitive as input. The output of the local model is the predicted interaction state. The prediction of the actual object states need to be extracted from this interaction state by reverting the initial transformation.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{PairwisePrediction.pdf}
	\caption{Concept of prediction in the pairwise interaction space with Abstract Collections. First the interaction state is computed. This state is then fed to the model together with the chosen action primitive. The AC Selector uses those to select the responsible Abstract Collection. The collection then uses its forward model to predict the next interaction state. The actual predicted object states are finally extracted from this interaction state.} 
	\label{fig:PairPrediction}
\end{figure}

\subsection{Planning}

%TODO
(TODO consider redoing the planning algorithm more similar to the way it is done
in the most recent model, which works, maybe the same ideas can be employed 
here)

In order to get a suitable action primitive given a target configuration, first the 
difference set between the current situation and the target 
configuration is computed. Afterwards, the Abstract Collection that corresponds to the same set of features is selected. In the case that this collection is not yet known, the 
most similar collection is chosen instead. In this context, the most similar Abstract Collection is the one that covers most of the changed features in the computed difference set. If multiple alternatives exist, one Abstract Collection is chosen at random. 

The selected Abstract Collection queries its own inverse model for the 
action that produces the output most similar to the desired target configuration. 

The action is then checked by consulting the already trained forward models. In case the forward models predict that the selected action does not reduce the difference to the target, a different action needs to be selected. This is done by querying a different abstract collection. Alternatively, a random action can be performed in order to produce new episodes. These in turn would improve both the forward as well as the inverse models of their respective abstract collections.

\subsection{Theoretical discussion}
%TODO do not really like this yet
Using pairwise interaction states in order to represent the interactions between objects is often used in robotics, for example in \cite{pairwiseExamples}. Its advantage is that it represents both objects involved in an interaction at the same time. This means that only one regression model needs to be trained in order to make predictions about both objects. In theory this should also make it less likely that impossible configurations are predicted such as solid objects being inside of each other. Furthermore, such an interaction state can contain all the necessary information about the objects in one representation. 

The downside of this approach is that the actual object states need to be inferred from these interaction states. While this will only involve simple coordinate transformations in most cases, some object attributes might not be as easily transformable. Furthermore, in order to contain all the necessary information about both objects, these interaction states can become high dimensional. 

Although the coupling of the two objects can have its advantages as stated above, the dependence between the objects can also be a problem when predicting. Since one of the two objects is represented relative to the coordinate frame of the other object, all predictions are also made with regard to the reference object's coordinate frame. In case the state of the reference object is not accurate, for example because of a sensor malfunction, the predictions for both objects will be influenced by this error. 

An even bigger disadvantage is the fact that this approach can not easily be extended to multiple objects. In environments with at least two objects and an actuator at least three pairwise interaction states are necessary: One for the first object and the actuator, one for the second object and the actuator and at least one for both objects. While one can argue for and against using the actuator as the reference object for the general case depending on the actual scenario, this decision is not trivial between two objects. Even if one finds suitable reference objects, there is still a problem with the extraction of the actual object states after prediction. All objects are part of at least two interaction states in this scene. Therefore, at least two extracted predictions exist for all objects in the environment. Unfortunately, these predictions are likely to be different from another. It is therefore required to compute a final prediction for each object which is not trivial in the general case. On top of that, the local models of the Abstract Collections need to be applicable to different objects, which makes them more complicated.

%Regardless of the used representation, the proposed concept might have further issues:
Regarding the Abstract Collections:
Unfortunately, no guarantees can be given about how well the interaction space is split. Depending on the used features, as well as the actual interaction scenarios that are encountered, some abstract collections might cover most of the interaction space. 

%TODO Maybe this is rather discussion?
%Furthermore, if the Abstract Collection Selector, selects wrong collections it is still possible to predict impossible configurations. Just consider the situation where the actuator is in contact with an object but the Abstract Collection Selector selects a collection where only the actuator changes its position. In this case the actuator would be predicted to be inside the object, although no such interaction state has ever been seen.

\section{Object space with gate \label{sec:gate}}

The alternative to modeling the interaction space, is to model each object and perform predictions for each object separately. 
The general components of this architecture are visualized in figure \ref{fig:GateOverview}.
The idea is to train local forward and inverse models for each object, or object group in the \textit{Predictor}. %TODO consider changing this name
Instead of distinguishing between different interaction scenarios as in the previous concept, objects that behave differently are distinguished. 
An object group can be considered a collection of objects that are similar in the way they behave during interactions. Therefore they can be represented by a single local model. One example would be two identically shaped block objects that only have different colors. In order to detect if two objects should be grouped together or not, one can start with training separate local models and compare their outputs. If two models appear to be similar, they can be merged together. Ideally, a similarity measure for objects is provided. Following the assumption that similar objects should behave similarly, such a measure would allow immediate grouping of objects.

Apart from the difference in representation, the other big difference in the two concepts is the introduction of the \textit{Gate}. The Gate is used to split the interaction space in two big subspaces. The first subspace represents all scenarios where no actual pushing interactions are taking place. That means that at most the actuator is moving due to some action primitives but no other object is influenced by those movements. Consequently, the other subspace contains all the scenarios where an object is influenced. When making predictions for the first subspace, it is sufficient to make predictions about the next state of the actuator. No knowledge about the behavior of the objects is required which also means that the local models do not need to be trained for these scenarios. The local object models only need to be trained on the scenarios where they are actually changed. 
There is no need to train multiple models for each object since the local subspaces each model need to learn are already a lot simpler than the interaction space learned in the previous concept.

In order to allow the local models to only train on this restricted subspace, this idea assumes that object states do not change without any interaction. The only exception is the \textit{Actuator}. Here, the actuator is treated as a special kind of object with its own forward and inverse model. These models can be provided beforehand or learned online. 
%The gate allows that the local forward and inverse models are only trained and tested in instances where there actually is interaction. Similar to the previous concept, this creates a subspace in the entire interaction space introduced before. The local models require less training data that way since they do not need to cover the entire interaction space. 

The current state of each object, including the actuator, is always updated when new information is received from the environment. At each update the gate and, if required the actuator's local models are trained. On top of that, the local models responsible for any object whose state changed with the last update, are trained as well.


\begin{figure}
	\centering
	\includegraphics{GateOverview.pdf}
	\caption{Overview of the concept about object state with gate. The actuator is a special object, that can be influenced directly. It's forward and inverse model might even be provided if known. For the other objects/object groups, the Predictor learns these models. The Gate learns a classifier to distinguish interactions between objects from only single object changes.} 
	\label{fig:GateOverview}
\end{figure}

\subsection{Prediction}

Because of the assumption that objects other than the actuator cannot change without any interaction, the way prediction is performed differs between the different object types. The actuator simply queries its own forward model with the selected action primitive in order to predict the next actuator state. 
The general process for predicting general objects is visualized in figure \ref{fig:GatePrediction}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{GatePrediction.pdf}
	\caption{Visualization of the prediction process for non actuator objects in the object space with gating concept. Using the predicted actuator state, relative interaction features are computed. These are used by the gate to determine if an interaction takes place or not. The responsible local forward model is used to predict the changes if an interaction is expected. From these changes the actual state prediction is computed.} 
	\label{fig:GatePrediction}
\end{figure}

First the next actuator state is predicted as mentioned above using the selected action primitive.
This predicted state is then used together with the current state of the object that is to be predicted to compute \textit{Relative Interaction Features}. These relative features are similar to the interaction state that was explained in the previous concept. However, since it is not necessary to extract the entire object states for both objects from these relative features, the dimensionality can be a lot lower than before. In fact, depending on the scenario, it may be sufficient to only represent the actuator in the local coordinate frame of the object. 
The \textit{Gate} then uses these features to determine if the object will be influenced by the new actuator state. If the gate predicts no interaction between the object and the actuator, the current object state is returned. 

On the other hand, if an interaction is predicted, the \textit{Predictor} uses the relative features to query the local forward model responsible for the current object to make a prediction. The local model predicts the changes in the object states instead of the final states. This allows the local models to be independent of the actual object states. The concept assumes, that an interaction between two objects behaves the same in different situations as long as their relative interaction features are the same. In order to get the actual predicted object state, these changes are added to the current object state.

When more then one object other than the actuator is present, the same process can be repeated. In order to predict interactions between two non actuator objects, a prediction chain is performed. First the actuator is predicted as described above. Afterwards, the objects that are directly influenced by the actuator are predicted. These predictions can then in turn be used as new \enquote{actuators} for interactions between them and other objects. 

%TODO decide which is used
%(STILL TO TRY) In order to predict multi object interactions, the gate function can be used to first collect all involved objects before
%invoking the appropriate predictor. (e.g. by interpolating the different input features).

\subsection{Planning}

Similar to prediction, planning is also performed differently depending on what kind of object is supposed to reach a given target configuration. In the case that the target object is the actuator, its inverse model is queried for an action primitive with the target configuration as input. 

The more interesting process of reaching a target configuration for a non actuator object is visualized in figure \ref{fig:GatePlanning}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{GatePlanning.pdf}
	\caption{Visualization of the planning process for non actuator objects in the object space with gating concept. }%TODO be more precise
		\label{fig:GatePlanning}
\end{figure}
	
First the current difference state is computed from the given target configuration and the current object state. This difference state is then used to query the responsible inverse model. Since only the actuator can be influenced by actions directly, these local inverse models do not directly return action primitives. Instead they return preconditions in the form of the relative interaction features. These features represent a situation where the object state is changed towards the target configuration. 
	
The current actuator state is then compared to these preconditions. If the actuator is already in a configuration where it meets these preconditions, an action primitive can be derived from the local features. In most situations this will however not be the case. The given preconditions will often require the actuator to be in a different position relative to the object that is to be moved. In these cases, the suitable position for the actuator, is used as a intermediate target. 

Considering the current object's position, an action is calculated to move the actuator towards the intermediate target. This might result in a circling movement of the actuator around the object. Moving the actuator directly towards the intermediate target position might result in moving the object in a more unfavorable position and is therefore avoided. Since these steps are performed at every timestep, the model can quickly adapt to changes in the environment.
	
\subsection{Theoretical discussion}

Representing each object by itself has the advantage, that no transformations are required. Furthermore, no object depends on the accuracy of another object's state. However, the biggest disadvantage is that if the gate makes errors in the classification than this concept can easily predict impossible configurations. 

Apart from the representation, this concept makes some more assumptions about the scenario then the previous one. The assumption that object states can only change through interactions with an actuator also means that an object does not continue sliding after it has been pushed. This makes restrictions about the possible weights of the objects and speeds of the actions.
%TODO rework/extend

\section{Time invariant inverse model \label{sec:invModel}}
	
%TODO redo after moving it here
Directly searching in the forward regression model for the inverse has several disadvantages in the given scenario: Firstly, the difference state that is computed can have features magnitudes greater than any change the local models have been trained with. In fact any target configuration that requires multiple timesteps to reach is already outside the range of the changes the forward models can have seen. 
The inverse model would need to extrapolate into unknown regions in these cases. Secondly, the features in the target state are not necessarily normalized. Therefore, the model does not necessarily know if a reduction of the difference in one feature is better than in another. This especially becomes a problem once only actions can be found that decrease the difference in one feature at the cost of an increase in another feature. Consider the example where a target position and orientation is given for an object. There might be situations where the object needs to be turned away from the target orientation in order to reduce the distance to the target position. In this case the orientation would need to be more or less ignored when using the inverse model to search for an action.

Furthermore, the output of the inverse model does not need to be as precise as the predictions of the forward model. This is mainly due to the fact that the inverse model is used to reach a target interactively. In the context of this thesis, there is no need to provide a sequence of precise action primitives that will then be executed blindly. Instead, as highlighted in figure \ref{fig:overview}, the model is tightly coupled with the environment. This means that the model is constantly updated and can adapt to changing situations. It is therefore sufficient for the inverse model to provide the means to make a step in the direction of the target configuration. In the context of the two concepts presented here, the means are not directly action primitives but rather preconditions that need to be fulfilled in order to be able to influence an object in a certain way.

In order to avoid the mentioned problems, a special inverse model is proposed that is trained separately from the forward model:
It is called \textit{time invariant inverse model} because, unlike a forward model, it does not focus on the actual quantity of the feature changes within one timestep. Instead, the inverse model focuses mainly on the direction of the changes. Furthermore, in order to avoid the problem of feature weighting feature importance, each feature is considered separately. 
Preconditions are grouped together according to the direction they change a certain feature in. An example of this grouping is visualized in figure \ref{fig:InverseModel}. 

\begin{figure}
	\centering
	\includegraphics{InverseModel2.pdf}
	\caption{Visualization of the precondition grouping in the proposed time invariant inverse model. All three pushing scenarios indicated by the three balls, will be grouped together since they all result in the same positional change.}
	\label{fig:InverseModel}
\end{figure}

The figure shows three different scenarios or preconditions in the form of the three balls that represent the actuator. In the forward model each precondition is tightly coupled to its resulting change. In this example the left situations results in exactly the small positional change upwards and a change in orientation. The same tight coupling is present with the other two situations. In the inverse model proposed here, all three situations are grouped together in one prototype responsible for a positional change upwards. Other prototypes exist for the two directions of change in orientation. This way one situation will be present in multiple prototypes if it caused multiple features to change.

Each prototype creates a weighted average\footnote{depending on the used features, a simple average does not work. See the implementation details in section \ref{sec:invModelRealization} for details.} of the preconditions for its feature and direction. The preconditions are weighted by their contribution towards the feature. In the example above, the preconditions for the middle scenario receive the strongest weight since they are responsible for the biggest change in position. 

When the inverse model is queried given some difference vector to the target configuration, a greedy strategy is used to first reduce the feature with the biggest difference. The prototype for the selected feature and its direction is then queried for the preconditions that will reduce the distance to the target configuration. 



	
