\chapter{Introduction}

%Motivate necessity
%State goals
%Structure of thesis
%What is the problem that we try to solve?
%Why is it relevant to solve it?

Inspired by the learning capabilities of humans, the field of machine learning tries to develop methods that allow machines to learn from data.
After decades of research a vast amount of powerful tools has been developed for machine learning. Each of these methods has its own advantages and disadvantages and are applicable to certain situations. Currently, research in machine learning is often performed by choosing a problem, e.g. image recognition or movement control, and trying to find and tune the most successful method to solve the chosen problem. This includes for example fine tuning the features that are used to represent the given data. This way the researchers were able to create better classifiers for image recognition (e.g. \cite{Liao20141187}) and better controllers for complex movements (e.g. \cite{NIPS2014_5444}). A good overview over different machine learning approaches can be found in the book by Bishop \cite{bishop2006pattern}.

In most of these cases the machine is trained to solve one specific problem. Depending on the chosen methods it is not possible to extend the machines knowledge easily without retraining the entire system afterwards due to the stability-plasticity-problem \cite{GROSSBERG198817}. More precisely because of the phenomenon of catastrophic forgetting\footnote{The phenomenon of forgetting previously learned information after receiving new information. Most prominent in neural networks and when trying to learn non-stationary data.} \cite{catastrophicForgetting1}.

In recent years, deep learning \cite{deepLearning2009,deepFrontier} has attracted a lot of attention by achieving great results in high dimensional tasks such as image classification \cite{deepImageClassification}. The ability of deep learning approaches to automatically extract relevant features from high dimensional data is one of the main reasons for the strong interest. However, so far deep learning requires a lot of training data to be successful which is the main reason why it is not further considered in this thesis.

With advances in robotic hardware and the successful application of machine learning in specialized tasks, such as image recognition, the goal of robotic research trends towards multi-purpose robots. However, a big problem for multi-purpose machines is that the current approach to machine learning is not applicable. Since the number of tasks the robot has to face is not known in advance, it is difficult to train suitable tools beforehand. Furthermore, even if one would attempt to train specialized parts for all kinds of problems, acquiring sufficient and accurate training data in advance is infeasible at best. On top of that, robotic platforms often only have limited computational resources which limits the amount of data they can process at once.

Therefore, instead of trying to train the machine beforehand, it might be better to provide the robot with the means to adapt to new situations on its own while it is encountering them. 
This continuous learning is also referred to as lifelong learning and resembles the human learning process more closely \cite{silver2013lifelong}.
Instead of learning a complete model\footnote{A model represents the robot's knowledge about the world.} on previously recorded training data, the robot adapts its model to the continuous stream of data while it is already using what it has learned so far. 
The biggest reason against such an continuous incremental approach is its difficulty. When incrementally training a single model to solve multiple different problems, the catastrophic forgetting effect is often experienced. Furthermore, different kind of tasks may require different features which makes training a single model infeasible. The usual approach is to learn local models for each task separately, however this introduces the need to recognize and distinguish the different problems in order to know which kind of local model the robot needs to employ.

Instead of challenging the entire problem of incrementally learning an unlimited number of arbitrary tasks, this thesis concentrates on the incremental learning of one task without prior training. 
While there are multiple machine learning methods that allow incremental updates, not all of them are suitable for this kind of task. 
First of all, the method should be as independent of prior knowledge or the used features as possible so that it can be used for a wide variety of task the robot might encounter. Furthermore, the update and query times of the chosen method need to be quick enough to allow continuous interaction with the environment. On top of that, the chosen method should not suffer from the catastrophic forgetting effect since the robot would constantly keep updating its model. 

One important aspect of general purpose robotics is object manipulation. In order to successfully interact with the objects in its environment the robot needs to learn what kind of interactions are possible and what their effects are. 
Furthermore, object interactions are hard to model manually as they follow complex dynamics. On top of that, different object can behave completely differently, so that knowledge acquired in previous training sessions might not be useful later on. Consequently, object interactions make an ideal target for online self adaptation. 

This thesis presents and compares two concepts that provide incremental learning of pushing interactions between an actuator\footnote{The part of a robot that acts upon its environment.} controlled by action primitives and some object in the environment.
While pushing interactions are only a very small subset of possible interactions a robot can have with objects, their dynamics still provide sufficient complexity to evaluate incremental learning systems. Since the behavior of differently shaped objects can vary a lot, learning about different kind of objects can even be regarded as learning similar but different tasks. 
The proposed concepts need to provide a forward model as well as an inverse model. The forward model makes predictions about the state of all entities in the environment after an action primitive has been performed. The inverse model provides an action primitive that is used to reach a specified target configuration within the environment.

Memory-based approaches, such as \gls{gng} have already been successfully used in robotic scenarios in order to solve the problems associated with incremental learning \cite{carlevarino2000incremental}. Due to their one-shot learning ability, memory-based methods can produce good prediction results from very little training data. It is for these reasons, that this thesis also focuses on a memory-based approach. An adaption of the \gls{gng} is developed and used as the underlying regression and classification method for the developed concepts. Furthermore, a prototype based inverse model is developed in order to allow extrapolation when deducing suitable action primitives.

The goal of this thesis can be summarized to provide and evaluate simple models that:

\begin{enumerate}
	\item Update themselves incrementally during the interaction
	\item Allow predictions of simple object interactions % with minimal domain knowledge
	\item Allow the deduction of action primitives required to reach a given target
\end{enumerate}

The remainder of this thesis is structured as follows: In chapter \ref{chap:stateOfTheArt} an overview of memory-based learning as well as an outline of recent research concerning incremental learning and object manipulation in the context of robotics is given. Two concepts were developed in order to fulfill the stated goals. Their general idea is described in chapter \ref{chap:concept} before concrete implementation details are given in chapter \ref{chap:modelReal}. These models are then evaluated with regards to the goal mentioned above in chapter \ref{chap:evaluation}. The evaluation is discussed in chapter \ref{chap:discussion} before this thesis thesis concludes in chapter \ref{chap:conclusion}.

