\chapter{Introduction}

%Motivate necessity
%State goals
%Structure of thesis
%What is the problem that we try to solve?
%Why is it relevant to solve it?


%TODO delete? Most likely not good...
%The defining quality that any agent, artificial or natural, requires is learning. Also used for many different 
%phenomenons, the term learning at its core means adaptation. The agent or some part of it adapts in order to
%better deal with its environment. Natural agents, especially humans, display impressive learning capabilities,
%allowing them to quickly adapt to ever changing environments and new tasks.
%
%In recent years, machine learning has come a long way in understanding and reproducing some of the learning
%capabilities of humans. We now have a wide range of different techniques and algorithms that can yield good
%classification and regression results. %TODO make glossary to explain what classification and regression is
%In introduction to these can for example be found in book by Bishop \cite{bishop}.
%
%The quality of the results achieved by machine learning is however more dependent on the chosen representation
%of the problem then on the actual technique used. For example it is generally not sufficient to use the raw audio signals 
%for speech recognition \cite{speechRecog}. Instead most speech recognizers use carefully selected pre-computed
%features that allow the underlying machine learner to correctly distinguish the words. 
%
%Because finding the best features is as challenging as learning a problem itself, a lot of focus as recently 
%shifted to deep learning \cite{deepLearning}. Deep learning is a technique that is inspired by the human brain and refers to
%training neural networks with many thousands of artificial neurons. Properly trained, these networks are capable of finding 
%relevant features in the presented data by themselves \cite{deepLearningFeatures}. Currently the biggest
%problem with deep learning is the required amount of training before the network can be used successfully. Although recent
%advances such as the development of Hinton's dropout technique \cite{dropout} allows to train bigger networks with fewer data,
%this criteria still limits the potential use cases of deep learning and neural networks in general.

After decades of research a vast amount of powerful tools have been developed for machine learning. A good overview can be found in the book by Bishop \cite{bishop}. Each of these methods has its own advantages and disadvantages and are applicable to certain situations. Currently, research in machine learning is often performed by choosing a problem, e.g. image recognition or movement control, and trying to find and tune the most successful method to solve the chosen problem. This way the researchers were able to create better classifiers for image recognition (e.g. \cite{imageRecList}) and better controllers for complex movements (e.g.\cite{movementList}).
%TODO Adrianas Anmerkung: 1. Im ersten Absatz würde ich das "e.g. image recognition or movement
%control" weglassen. Das kommt direkt im nächsten Satz schon wieder
%(und image recognition im 3. Absatz noch einmal), das stört dann etwas
%den Lesefluss, wenn man so denkt "häh, déjà vu?!"


In most of these cases the machine is trained to solve one specific problem. Depending on the chosen methods it is not possible to extend the machines knowledge easily without retraining the entire system afterwards because of the stability-plasticity-problem \cite{stability-plasticity}. More precisely because of the phenomenon of catastrophic forgetting \cite{catastrophicForgetting1}.

With advances in robotic hardware and the successful application of machine learning in specialized tasks, such as image recognition, the goal of robotic research trends towards multi-purpose robots. However, the biggest problem for multi-purpose machines is that the current approach to machine learning is not applicable. Since the number of tasks the robot has to face is not known in advance, suitable tools cannot be training in advance. Furthermore, even if one would attempt to train specialized parts for all kinds of problems, acquiring sufficient and accurate training data beforehand is infeasible at best. 
%TODO glossary for model or some footnode on what is meant by model
Therefore, instead of trying to train the machine beforehand, it might be better to provide it with the means to adapt to new situations on its own while it is encountering them. Instead of learning on previously recorded training data, the robot adapts its model to the continuous stream of data while it is already using what it learned beforehand. The biggest reason against such an continuous incremental approach is its difficulty. When incrementally training a single model to solve multiple different problems, the catastrophic forgetting effect is usually experienced. The usual approach is learn local models for each task separately, however this introduces the need to recognize and distinguish the different problems in order to know which kind of local model the robot needs to employ. 

Instead of challenging the entire problem of incrementally learning an unlimited number of arbitrary tasks, this thesis concentrates on the incremental learning of one task without prior training. 
While there are multiple machine learning methods that allow incremental updates, not all of them are suitable for this kind of task. First of all, the method should be as independent on prior knowledge as possible so that it can be used for a wide variety of task the robot might encounter. Furthermore, the update and query times of the chosen method need to be quick enough to allow continuous interaction with the environment. On top of that, the chosen method should not suffer from the catastrophic forgetting effect since the robot would constantly keep updating it. For this thesis a memory based learning approach was chosen in order to solve these problems. Due to their one-shot learning ability, memory based methods can produce good prediction results from very little training data. 

One important aspect of general purpose robotics is object manipulation. In order to successfully interact with the objects in its environment the robot needs to learn what kind of interactions are possible and what their effects are. 
Furthermore, object interactions are hard to model manually as they follow complex dynamics. On top of that, different object can behave completely differently, so that knowledge acquired in previous training sessions might not be useful later on. It is for these reasons object interactions make an ideal target for online self adaptation. 

This thesis provides two concepts that provide incremental learning of pushing interactions between an actuator controlled by action primitives and some object in the environment.
While pushing interactions are only a very small subset of possible interactions a robot can have with objects, their dynamics still provide sufficient complexity to evaluate incremental learning systems. Since the behavior of differently shaped objects can vary a lot, learning about different kind of objects can even be regarded as learning similar but different tasks.%TODO Maybe more on this?
The proposed concepts need to provide a forward model as well as an inverse model. The forward model makes predictions about the state of all entities in the environment after an action primitives as been performed. The inverse model provides an action primitive that is used to reach a specified target configuration within the environment.

The goal of this thesis can summarized to provide and evaluate simple models that:

\begin{enumerate}
	\item Update themselves incrementally during the interaction
	\item Allow prediction and planning of simple object interactions % with minimal domain knowledge
	\item Allow lifelong learning
\end{enumerate}

This thesis is structured as follows: In chapter \ref{chap:stateOfTheArt} an overview over memory based learning as well as recently proposed models for learning object interactions for robotics is given. Two concepts were developed in order to fulfill the stated goals. Their general idea is described in \ref{chap:concept} before concrete implementation details are given in chapter \ref{chap:modelReal}. These models are then evaluated with regards to their prediction and planning performance in chapter \ref{chap:evaluation}. Finally, this thesis concludes with a discussion of these results in chapter \ref{chap:conclusion}.

