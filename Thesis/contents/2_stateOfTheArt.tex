\chapter{Related Work \label{chap:stateOfTheArt}}


%What kinds of interaction models are there
%Incremental/online models
%Memory based approaches
%What have others tried to solve this/similar problems?

%TODO mention at least one paper where a pairwise interaction representation is used!
% I.e try talking bout grasping, problems with only learning, human representation
\section{Memory-based models}

In machine learning, one generally assumes that data, for example class labels, are given by some function $f^*$. Given some training data $D$ with $d^i =(\vec{x}^i,\vec{y}^i)$ where $\vec{x}^i$ represents the given input and $\vec{y}^i$ the corresponding output of the $i$'s data point, one tries to estimate $f^*$. 
Although different algorithms approximate $f^*$ differently, they can be categorized in two general families: The first one tries to detect \textit{correlations} between features in order to make predictions. The simplest example for this is given by the linear regression \cite{linearRegression} where the goal is to find weights $w_j$ so that $f(\vec{x}) = \sum w_j \cdot x_j$. 

The other family focuses more on \textit{similarities} in the input space instead of feature correlations. On of the most prominent examples for this is the \gls{knn} regression \cite{kibler1987learning}. Previously seen training data is stored and compared to new input data. New input data $\vec{x}$ is then labeled according to the $k$ closest stored instances. The easiest form is to average the outputs of the $k$ closest instances around $\vec{x}$ (here denoted as the set $N(\vec{x}$)):
\begin{equation}
\vec{y}_{new}(\vec{x}) = \frac{1}{k} \sum_{\vec{y} \in N(\vec{x})} \vec{y}
\end{equation}

These instances are also often called prototypes, if only a few instances are used to represent a subspace in the input space instead of all training instances. Since the closest instance is determined by similarity, the used features and metric is usually critical for these methods (see for example \cite{metric1, metric2}). This dependence on careful preprocessing of the used features and metric can be considered the biggest disadvantage of these methods. However, there is a lot of ongoing research regarding automatically adapting the used metric while training in order to better fit the data, e.g. by Hammer et al. \cite{lvq}. Unfortunately, online metric adaptation needs a lot of iterations before yielding satisfying results in most cases. 

Another disadvantage of memory-based models is the memory consumption over time. Since the training examples need to be stored in order to be retrieved later, a lot of memory can be consumed. This can lead to increased query and update times, since these scale linearly with the number of stored instances. In 1991 Geva et al. showed that the number of required instances can be reduced depending on the used algorithm \cite{protReduction}. Extending the area of influence of the given instances, for example by using \glspl{llm} \cite{LLM}, can further decrease the number of required instances.

The advantages of memory- or instance-based models is that they are local by design. This means that their output only depends on a small part, located around the given input, of the model. Likewise, when they are updated by adding or removing some stored instances, they do so based on local criteria. This is also the reason why memory-based models usually do not suffer from the catastrophic forgetting phenomenon.

Another reason to look into memory-based learning is the evidence for episodic memory in humans \cite{tulving2002episodic}. These findings suggest that humans store past experiences in order to utilize them in new situations. This general idea is applied in memory-based learning approaches.

For the implementation of the concepts developed in this thesis, an adaptation of the \gls{gng} using \gls{llm} as output function is used as underlying regression and classification model. This adaptation is called \gls{aitm} for the remainder of this thesis and is explained in section \ref{sec:ITM} in detail.

%consider putting it in, when we actually talk about exploration
%\section{Learning forward and inverse models}
%
%Much research in the field of robotics has gone into learning forward and inverse models for robot control \cite{listOfControlPaper}. 
%
%
%\item \cite{baranes2013active} Robot architecture for active, online learning of forward and inverse models
%\begin{itemize}
%	\item Limited to only the robot, not including external objects and their interactions
%	\item Highlights some of the challenges when trying to (actively) learn online
%\end{itemize}

\section{Incremental online learning}

In order to deal with non stationary data, i.e. data whose characteristics change over time, as well as processing data streams continuously with limited resources, incremental learning is gaining increasing attention \cite{polikar2014guest}. Usually memory- or instance-based approaches are adapted to allow incremental training, such as the \gls{svm} for classification \cite{diehl2003svm}. Non stationary data as well as limited processing power are two constraints researchers in the field of robotics have to deal with. As such, the robotic research community is focusing more on the use of such methods: 
Carlevarino et al. successfully train an adaption of the \gls{gng} to incrementally learn an inverse model for robot control \cite{carlevarino2000incremental}. 
Losing at al. use a different memory based approach with the \gls{lvq} in order to incrementally train an obstacle classifier on a robotic platform \cite{losing2015interactive}.
Unfortunately, all these works require a relative large amount of training examples before a good performance is achieved. In the situation discussed in this thesis, the developed model should be able to produce reasonable results with only a few interactions.

Liu et al. propose an biology-inspired adaptation of the \gls{mdp} by using episodic memories \cite{liu2015robotic, roboticEpisodes}. Their approach incrementally learns an experience map of an uncertain environment. 
Unfortunately, their approach requires the definition of fixed goal states or targets. Furthermore, transitions between different goals are difficult since one episode, or one EM-MDP if learned for each goal. 
In the scope of this thesis, a robot should be able to learn about the interactions in the environment without being provided additional information, such as goal states or rewards for subgoals, by humans.

\section{Learning object interactions}

\subsection{Human object manipulation}

While it was never the goal of this thesis to provided biology-inspired models of object interactions, there are some indications in recent findings that suggest similar processes in human brains as the ones developed here: \\
A good overview about recent findings in neurobiology is given in \cite{flanagan2006control}. One of these findings suggest that contact events are especially important in order to synchronize multi-modal information \cite{johansson2001eye}. 
While it is not enough to wait for a contact event in this context, the second concept, described in section \ref{sec:gate} trains a gating function specifically designed to predict when one object influences another.

Already in 1999, Kawato analyzed internal object specific forward and inverse models in humans \cite{kawato1999internal}. Multiple studies have been performed successfully in order to find evidence of the existence of internal object specific models, e.g. \cite{flanagan2001sensorimotor, merfeld1999humans}.
Both developed concepts employ local models in order to reduce the size of the learned space. Especially the findings of Flanagan et al. \cite{flanagan2001sensorimotor} that suggest size-weight specific internal models for objects correlates to the employed idea to train local models for different object groups in the second concept.

\subsection{Robotic object manipulation}

Robots are supposed to interact with and manipulate their environment in order to be useful. Therefore, a lot of research is being done regarding object manipulation.

Much of the earlier work regarding object manipulation was concentrated in grasping objects. A good overview on different approaches and challenges is provided in \cite{graspingReview}. Having determined successful grasp types and strategies, more recent work combines grasping with other modalities such as vision \cite{graspingVision}. Here Saxena et al. train their system to detect suitable grasp locations in images from novel objects.
Deep learning is also used for the same problem in order to avoid crafting features by hand \cite{graspingDeep}. 
While grasping is very important for general-purpose robots, the proposed solutions do not learn about the object's dynamics. In fact these systems are usually considered trained successfully if the objects do not move until they have been grasped. 
This thesis on the other hand concentrates on learning object dynamics as an exemplary scenario for the incremental acquisition of knowledge in unknown environments.

Once objects have been grasped the robot still needs to learn to manipulate them in a desired way. In most cases, a policy\footnote{A policy defines what action primitive is to be used depending on the current situation and target.} is learned in order to reach a given target configuration. Many different methods of learning policies in different scenarios have been proposed. A good overview on different strategies developed for robotics is given by Deisenroth et al. \cite{deisenroth2013survey}. Recently, Levine et al. achieve great results in learning policies of complex dynamics such as assembling plastic toys \cite{levine2015learning}. The authors report that they require much fewer training iterations than earlier policy search approaches. They achieve this by training linear-Gaussian controllers on trajectories which are later combined by a guided policy search component.
However, the main difference to the given problem for this thesis is that Levine et al. consider the objects already firmly grasped which eliminates most of the dynamics in the interaction between the grasped object and the actuator.

Other works are often training in an offline fasion, e.g. 
\cite{nishide2008predicting, moldovan2012learning, contactPrediction}. Out of these, the works of Moldovan et al. and Kroemer et al. are most notable:
Moldovan et al. use a probabilistic approach to learn affordance models useful for object interactions \cite{moldovan2012learning}. Affordances, as introduced by Gibson \cite{affordances}, describe the relations between object, actions and effects. Moldovan et al. are able to extend their approach to multiple object scenarios. The biggest difference of their approach to the here presented one, apart from the required offline training and tuning, is that it uses more prior knowledge in order to construct a suitable \gls{bn}.

More recently, Kroemer et al. developed a memory-based model that uses the similarities of contact distributions between objects in order to classify different kind of interactions \cite{contactPrediction}. In their work an interaction is given if one object supports another object or if an object can be lifted given a certain grasp configuration. The approach of Kroemer et al. works with multiple objects. Since only the contact distributions between two objects are considered, a classification can be made for each object pair separately. Unfortunately, their approach is limited to binary predictions of predefined interaction classes. The robot still needs to learn a suitable forward and inverse models in order to manipulate the objects. Furthermore, their proposed sampling approach shows poor performance and is likely to become infeasible in unconstrained complex environments.

The most similar work to this thesis both in terms of setting and in their approach has been done by 
Lau et al. \cite{pushing}. The authors use \gls{knn} regression to make predictions about pushing an object. They also provide an algorithm to extract suitable actions that allow to push the object towards a specified target. Unfortunately, the authors restrict their model to the pushing interaction: Moving the actuator around or towards the object is not part of the learned model but is provided instead. Furthermore, while they describe their approach to work with position and orientation, they only provide results for position. 

Overall it can be said, that a lot of research is being done regarding online learning and object manipulation in robotics. Many of these approaches are memory- or prototype-based since memory-based approaches can work well under the conditions in robotic scenarios such as non stationary and limited data. 
This thesis combines ideas from different approaches, such as using local models and episodic like memory, in order to incrementally learn about an unknown environment.

