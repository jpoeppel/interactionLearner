\chapter{Related Work \label{chap:stateOfTheArt}}


%What kinds of interaction models are there
%Incremental/online models
%Memory based approaches
%What have others tried to solve this/similar problems?
%TODO get authors automatically

%TODO mention at least one paper where a pairwise interaction representation is used!
%TODO Need a lot more than this!!!
% I.e try talking bout grasping, problems with only learning, human representation
\section{Memory based models}

In machine learning, one generally assumes that data, for example class labels, are given by some function $f^*$. Given some training data $D$ with $d^i =(\vec{x}^i,\vec{y}^i)$ where $\vec{x}^i$ represents the given input and $\vec{y}^i$ the corresponding output of the $i$'s data point, one tries to estimate $f^*$. 
Although different algorithms approximate $f^*$ differently, they can be categorized in two general families: The first one tries to detect \textit{correlations} between features in order to make predictions. The simplest example for this is given by the linear regression \cite{linearRegression} where they find weights $w_j$ so that $f(\vec{x}) = \sum w_j \cdot x_j$. 

The other family focuses more on \textit{similarities} in the input space instead of feature correlations. On of the most prominent examples for this is the \gls{knn} regression \cite{kibler1987learning}. Previously seen training data is stored and compared to new input data. New input data $\vec{x}$ is then labeled according to the $k$ closest stored instances. The easiest form is to average the outputs of the $k$ closest instances around $\vec{x}$ (here denoted as the set $N(\vec{x}$)):
\begin{equation}
\vec{y}_{new}(\vec{x}) = \frac{1}{k} \sum_{\vec{y} \in N(\vec{x})} \vec{y}
\end{equation}

These instances are also often called prototypes, if only a few instances are used to represent a subspace in the input space. Since the closest instance is determined by similarity, the used features and metric is usually critical for these methods (see for example \cite{metric1, metric2}). This dependence on careful preprocessing of the used features and metric can be considered the biggest disadvantage of these methods. However, there has also been a lot of research in automatically adapting the used metric while training in order to better fit the data, e.g. by Hammer et al. \cite{lvq}. Unfortunately, online metric adaptation often needs a lot of iterations before yielding satisfying results. 

Another disadvantage of memory based models is the memory consumption over time. Since the training examples need to be stored in order to be retrieved later, a lot of memory can be consumed. This can also lead to increased query and update times, since these scale linearly with the number of stored instances. In 1991 Geva et al. \cite{protReduction} showed that the number of required instances can be reduced depending on the used algorithm. Extending the area of influence of the given instances, for example by using \glspl{llm} \cite{LLM}, can further decrease the number of required instances.

The advantages of memory or instance based models is that they are local by design. This means that their output only depends on a small part, located around the given input, of the model. Likewise, when they are updated by adding or removing some stored instances, they do so based on local criteria. This is also the reason why memory based models usually do not suffer from the catastrophic forgetting phenomenon.

Another reason to look into memory based learning is the evidence for episodic memory in humans \cite{tulving2002episodic}. These findings suggest that humans store past experiences in order to utilize them in new situations. This general idea is applied in memory based learning approaches.

For the implementation of the concepts developed in this thesis, an adaptation of the \gls{gng} using \gls{llm} as output function is used as underlying regression model. This adaptation is called \gls{aitm} for the remainder of this thesis and is explained in section \ref{sec:ITM} in detail.

%TODO consider putting it in, when we actually talk about exploration
%\section{Learning forward and inverse models}
%
%Much research in the field of robotics has gone into learning forward and inverse models for robot control \cite{listOfControlPaper}. 
%
%
%\item \cite{baranes2013active} Robot architecture for active, online learning of forward and inverse models
%\begin{itemize}
%	\item Limited to only the robot, not including external objects and their interactions
%	\item Highlights some of the challenges when trying to (actively) learn online
%\end{itemize}

\section{Incremental online learning}

In order to deal with non stationary data, i.e. data whose characteristics change over time, as well as processing data streams continuously with limited resources, incremental learning is gaining increasing attention \cite{polikar2014guest}. Usually memory or instance based approaches are adapted to allow incremental training, such as the \gls{svm} for classification \cite{diehl2003svm}. Carlevarino et al. successfully train an adaption of the \gls{gng} to incrementally learn an inverse model for robot control \cite{carlevarino2000incremental}. 
Losing at al. use a different memory based \gls{lvq} in order to incrementally train an obstacle classifier on a robotic platform \cite{losing2015interactive}.
Unfortunately, all these works require a relative large amount of training examples before good performance was achieved. In the situation discussed in this thesis, the developed model should be able to produce reasonable results with only a few interactions.

Liu et al. propose an biology-inspired adaptation of the \gls{mdp} by using episodic memories \cite{liu2015robotic, roboticEpisodes}. Their approach incrementally learns an experience map of


\section{Learning object interactions}

\subsection{Human object manipulation}

A good overview about recent findings in neurobiology is given in \cite{flanagan2006control}. One of these findings suggest that contact events are especially important in order to synchronize multi-modal information \cite{johansson2001eye}. The developed gating function in the second concept (see section \ref{sec:gate}) serves a similar idea. 
Already in 1999, Kawato analyzed internal object specific forward and inverse models in humans \cite{kawato1999internal}. Multiple studies have been performed successfully in order to find evidence of the existence of internal object specific models \cite{flanagan2001sensorimotor, merfeld1999humans}.
These findings motivate the use of local interaction or object specific models in this thesis.

\subsection{Robotic object manipulation}

Because of the importance for robotics, a lot of research is being done regarding object manipulation. Because robots are expected to use tools, much research is being done regarding grasping. A good overview on different approaches and challenges is provided in \cite{graspingReview}. Having determined successful grasp types and strategies, more recent work combines grasping with other modalities such as vision \cite{graspingVision}. Here Saxena et al. train their system to detect suitable grasp locations in images from novel objects.
Deep learning is also used for the same problem in order to avoid crafting features by hand \cite{graspingDeep}. 
While grasping is very important for general-purpose robots, the proposed solutions do not learn about the object's dynamics. In fact these systems are usually considered trained successfully if the objects do not move until they have been grasped.

Once objects have been grasped the robot still need to learn to manipulate them in a desired way. In most cases, a policy\footnote{A policy defines what action primitive is to be used depending on the current situation and target.} is learned in order to reach a given target configuration. 

However, most systems are trained in an offline fashion \cite{nishide2008predicting, moldovan2012learning, contactPrediction}. Out of these, the works of Moldovan et al. and Kroemer et al. are most notable:
Moldovan et al. use a probabilistic approach to learn affordance models useful for object interactions in \cite{moldovan2012learning}. Affordances, as introduced by Gibson \cite{affordances}, describe the relations between object, actions and effects. Moldovan et al. are able to extend their approach to multiple object scenarios. The biggest difference of their approach to the here presented one, apart from the required offline training and tuning, is that it uses more prior knowledge in order to construct a suitable \gls{bn}.

More recently, Kroemer et al. developed a memory based model that uses the similarities between contact distributions between objects in order to classify different kind of interactions \cite{contactPrediction}. In their work an interaction is given if one object supports another object or if an object can be lifted given a certain grasp configuration. The approach of Kroemer et al. works with multiple objects, since only the contact distributions between two objects were considered. Unfortunately, their approach is limited to binary predictions of predefined interaction classes. The robot still needs to learn a suitable forward model. Furthermore, their proposed sampling approach shows poor performance and is likely to become infeasible in unconstrained complex environments.

Learning object interactions incrementally has also been done:
Levine et al. achieve great results in learning policies of complex dynamics  %TODO \gls{policy}.
such as assembling plastic toys \cite{levine2015learning}. They require much fewer training iterations than earlier policy search approaches, i.e \cite{otherPolicySearchs}. They achieve this by training linear-Gaussian controllers on trajectories which are later combined by a guided policy search component.
However, the main difference to the given problem for this thesis is that Levine et al. consider the objects already firmly grasped which eliminates most of the dynamics in the interaction between the grasped object and the actuator.

The most similar work to this thesis both in terms of setting and in their approach has been done by 
Lau et al. \cite{pushing}. The authors use \gls{knn} regression to make predictions about pushing an object. They also provide an algorithm to extract suitable actions that allow to push the object towards a specified target. Unfortunately, the authors restrict their model to the pushing interaction: Moving the actuator, here the entire circular mobile robot, around or towards the object is not part of the learned model but provided instead. Furthermore, while they describe their approach to work with position and orientation, they only provide results for position. 


[TODO]
\begin{itemize}
\item more
\item Human object manipulation
\item grasping?
\item ...
\item Summary at the end
\end{itemize}
%Although, developed from a different point of view, the work presented here can be considered an extension to their work. Especially the proposed alternative inverse model (see section \ref{sec:invModel}) 

%\begin{itemize}
%	\item \cite{pushing} Paper using similar idea of instance based memory in order to predict pushing
%	\begin{itemize}
%		\item restricted to only pushing interactions (no getting closer etc learned by model)
%		\item is mainly used to move object to target position
%		\item General strategy is the same as in my model: First figure out preconditions, then perform best action
%		\item Uses nearest neighbor to find best action
%		\item Works for complex shaped objects
%		\item Paper only shows results based on position, not orientation
%		
%	\end{itemize}
%	\item \cite{nishide2008predicting} RNN and HNN system that learns interactions between objects from camera images
%	\begin{itemize}
%		\item Tries to solve more complex problem (includes feature extraction from images in the system)
%		\item But is learned in a batch mode. Prerecorded by controlling the robot and training on recorded images (~ 20min offline)
%		\item They call it \textit{active sensing} regardless
%	\end{itemize}
%	\item \cite{baranes2013active} Robot architecture for active, online learning of forward and inverse models
%	\begin{itemize}
%		\item Limited to only the robot, not including external objects and their interactions
%		\item Highlights some of the challenges when trying to (actively) learn online
%	\end{itemize}
%	\item \cite{flanagan2006control} Recent (2006) paper about human object manipulation control strategies
%	\item \cite{moldovan2012learning} Learning object affordances with probabilistic model. Actually extends to multiple objects
%	\item \cite{levine2015learning} Impressive (batch) results of object manipulation.
%	\begin{itemize}
%		\item Restriction is that objects are fixed to robot
%		\item Basically \textit{only} learns a trajectory
%	\end{itemize}
%	\item \cite{contactPrediction} Exemplar-based learning of contact/support interaction between (multiple) objects.
%	\begin{itemize}
%		\item Contact distributions are estimated from contact points extracted from the point clouds of objects
%		\item Similarity between distributions determines whether the given contact allows a special interaction
%		\item Binary classification if a certain interaction is possible/happening
%		\item Does not make predictions about the future state of the interacted objects
%		\item Has not been trained online, but rather with previously labeled training data
%	\end{itemize}
%	\begin{itemize}
%		\item Look at experience graphs
%		\item Can be mentioned here as well (\cite{phillips2012graphs}) as somewhat similar idea regarding the use of previous experiences, maybe better in introduction?
%	\end{itemize}
%\end{itemize}
