\chapter{Conclusion \label{chap:conclusion}}


%Discuss pro's and cons of concepts/realisations
%What are the reasons for good/poor results?
%What are the limitations of the ideas/realisations?
%How much do the ideas/realisations solve the initially stated problems?
%How do these results/ideas relate to other previous work?
%What could be possible improvements?
%TODO more in response to related work
The initial goal of this thesis were as follows:
Provide simple (memory-based) models that
\begin{enumerate}
\item Update themselves incrementally during the interaction
\item Allow prediction of simple object interactions
\item Allow the deduction of action primitives required to reach a given target
\end{enumerate}
in the context of simple object interactions.

In order to meet these goals, the two concepts described in chapter \ref{chap:concept} were developed and implemented as described in chapter \ref{chap:modelReal}. 
The first requirement was enforced by the given framework which requires the implementations to be updated and queried quickly. Furthermore, the open loop evaluation in chapter \ref{chap:evaluation} showed one-shot learning capabilities of the developed regression and classification model which is an extension of the well known \gls{gng} similar to the work of Carlevarino et al.\cite{carlevarino2000incremental}.

In the other evaluated tasks it was shown, that both other requirements were at least partly fulfilled since prediction up to 150 steps into the future were possible without preprocessing the used features, or using special metrics. 

Reaching target positions incrementally is mostly successful as long as all possible interaction types have been experienced using a lightweight inverse model which is explained in section \ref{sec:invModel}. By not also predicting and reaching positions but also orientations, these concepts outperform the work in \cite{pushing} at least for simple objects while requiring less training data. 

Overall, this thesis demonstrated that incremental learning in unknown environments is possible with very limited domain knowledge. Different representations can be used where some make more assumptions about the domain (the object state concept) than other (the interaction state concept).



%\begin{itemize}
%	\item Compare to related work where possible (especially with \cite{pushing})
%	\item Discuss if goals are met, or to what extend they are met
%	\item Discuss model limitations (i.e. what will it never be able to do) (consider including possible extensions/solutions directly with the limitations))
%	\begin{itemize}
%		\item Extrapolation to unseen interactions
%		\item Reliance on \enquote{velocity} ?
%		\item Interaction vector required
%		\item Current representation does not account for local differences in the world (only relative features are considered, the absolute position in the world is not taken into account)
%		\item Inverse model/circling can get stuck on loop in rare occasions, due to numeric problems
%	\end{itemize}
%\end{itemize}

\section{Limitations}

\section{Future work/possible improvements}

\begin{itemize}
\item Combine both models: Add gating function to interaction model
\end{itemize}