\chapter{Model realization\label{chap:modelReal}}


%Detailed enough to be able to reproduce
%Pseudocode where applicable
%Explain along figure?
%Include technology that's used
%How did we realize/achieve the ideas?
%Present what kind of assumptions/prior knowledge is made!!

\begin{itemize}
	\item Actual architectures resemble concepts closely
	\item Crux lies in the regression model (AITM)
\end{itemize}

In order to evaluate the developed ideas, prototypes of the two concepts described in the previous section have been implemented in Python. Both prototypes are developed as such that they can be evaluated in the same way in the next chapter. The implementations try to follow the presented concepts very closely. As such the general data flow is the same as was presented in the figures  \ref{fig:PairPrediction}, \ref{fig:GatePrediction} and \ref{fig:GatePlanning}.
Relevant decisions and assumptions made specifically for the implementation are highlighted and explained in this chapter. %TODO maybe needs to be changed

Section \ref{sec:basics} starts with describing common design decisions made that apply to both concepts. Afterwards the relevant implementations details regarding the two prototypes are presented in section \ref{sec:pairRealization} for the interaction state concept and in section \ref{sec:gateRealization} for the object state concept. Finally, section \ref{sec:technologies} describes the used technologies such as the underlying regression and classification model and the implementation of the inverse model in detail.

\section{Basics \label{sec:basics}}

%The following descriptions and assumptions are accurate for all realizations independent of the underlying concept.

%\subsection{Single timestep}
%TODO consider if this makes sense/is required
%One way to learn pushing interactions is to learn the trajectories of entire interactions. While this is possible, for example with a Hidden Markov Model \cite{hmm} and has been done successfully by [TODO look up name] \cite{hmmTrajectory}, it requires labeled training data. %TODO
%More precisely, it requires the models to know when a trajectory starts and when it finishes. Since the model presented here are supposed to learn incrementally by self exploration or at least in an online manner without being provided labeled data from the outside, the models would need to derive the start and endpoints of an interaction automatically. 
%
%The models presented here do not predict entire interactions but rather make small predictions at each timestep in order to avoid the need for such segmentation. This also means that these models are coupled closely to their environment and get updates at each timestep. The actual duration between two updates is not predetermined or restricted by the models presented here. The longer the duration between updates, the more the object states change during an interaction. 
%TODO maybe rearrange the sentences

\subsection{Available information about objects}

The kind of information that is provided by the environment obviously depends on the sensors that are available to the robot. From the information provided by these sensors, features can be computed. The models themselves are greatly independent on what features are actually used. In fact the models do not require any knowledge about what the features represent for prediction and none is provided. This allows the exact same model to be used in various settings with different features, for example if additional or different sensors are available. In order to yield good results, the used features obviously need to have the necessary expressiveness.

Unfortunately, the model does need to have some partial knowledge about the features when it comes to planning as will be further explained in the corresponding sections of both models.

These prototypes were evaluated using a physics simulation, further explained in section \ref{sec:simulation}. From this simulation the information in table \ref{tab:availInformation} is provided for each object at each update.

\begin{table}[h!]
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill} } l l}
		\textbf{Feature} & \textbf{Description} \\ 
		\hline \hline 
		x Position & Global x position of the object \\
		y Position & Global y position of the object \\
		Orientation & Global orientation around the z-axis of the object \\
		x Velocity & Global x velocity of the object \\
		y Velocity & Global y velocity of the object \\
		\hline 
	\end{tabular*} 
	\caption{Summary of all information about objects that is available at each update step from the environment in the given setting.}
	\label{tab:availInformation}
\end{table}

Furthermore,  a unique identifier, the shape and size of the objects are known and can be used to compute additional features for the model. What kind of features are computed from this information is a design decision of the user of these models. Because of the dependence on the used metric in the underlying regression model, using more features might worsen the performance of the models. 



\subsection{Action primitives}
In the scope of this thesis, the action primitives allow to set the two dimensional velocity of the actuator. Although, velocities are set, the models assume that an action is selected and performed at every iteration. In general, the nature of the action is not all that important to the models as long as it can be represented as a vector. In this case a two dimensional vector is used representing the x- and y-velocity respectively. The velocities are given according to the global coordinate system of robot. 

\subsection{Used regression and classification model}

As already stated in the introduction and motivated in chapter \ref{chap:stateOfTheArt}, this thesis uses a memory based approach to learn the interactions. For this end, a special adaptation of the \gls{gng} has been developed which can be used for regression as well as classification tasks. This \gls{aitm}, explained in section \ref{sec:ITM}, is used for all regression and classification models used in both prototypes unless otherwise mentioned. 

\subsection{Using local features and predicting differences}
%\begin{itemize}
%\item Local features make the assumption that everything behaves the same regardless of the configuration
%\item Difference prediction needs to be used when using local features
%\item Difference prediction is also possible with global features and without the assumption
%\item Difference prediction reduces output space, not sure if I want to write about this
%\end{itemize}
Both prototypes only use local features as inputs for their trained regression and classification models. 
Local features mean that all features are represented relative to some reference object's coordinate frame. The exact computation of the features is explained in sections \ref{sec:intFeatures} for the interaction model and \ref{sec:gateFeatures} for the object state model.
Using local features assumes that similar interactions behave identical regardless where in the environment they take place. 
Only the local relations between the involved objects determine the outcome of the interaction. 
For the given task of pushing interactions this assumption will hold true as long as the environment only has a constant effect on the objects. The environment used for the evaluations, described in section \ref{sec:environment}, fulfills these conditions since it only affects the objects through gravity and friction, which are constant throughout the entire environment. 

The great advantage of this approach is that the interactions can be learned regardless of the object's actual configuration in the environment. In fact training data from all configurations can be used to learn a certain interaction. Furthermore, this approach provides free generalization to any configuration in the environment without the need of additional training data.

In more realistic environments, where this assumption does not hold true, the differences can still be used. However, in this case, the used input features need to contain the information about the influence of the environment or the current object configuration. Depending on the actual scenario and its dynamics, this might require absolute global features which offer a lot less generalization.

An additional consequence of these local features is that the forward models of both concepts can only predict the changes instead of resulting features. As already stated in the two concept descriptions, the actual predictions for the interaction state and the object state are computed by adding these predicted changes to the current states.
Without knowledge about the actual position in the input data, the actual position after an interaction cannot be predicted. However, this is not a problem but rather a benefit. Changes are limited in their size compared to the resulting features. 
Consider the feature position: An object cannot change its position from one timestep to another arbitrarily, but rather only by a certain maximum amount. When predicting changes, the learner's output only needs to cover the subspace defined by this maximum amount instead of the entire space. Furthermore, this approach of only predicting the changes can also be applied when using global input features. The models themselves are therefore not restricted by this.


\section{Modeling pairwise interaction \label{sec:pairRealization}}

%\begin{itemize}
%	\item feature selection? (currently not implemented in latest version)
%\end{itemize}

The implementation of the pairwise interaction model also contains the components visualized in figure \ref{fig:PairOverview}. From these components, three different parts are trained:
The Abstract Collection Selector trains a classifier that selects any of the $n$ learned Abstract Collections. Within each Abstract Collections, there exist a local forward model which performs the predictions. Additionally, the Abstract Collections contain an inverse model, which return preconditions that result in a specific change of the interaction state. The forward model as well as the selector both use the same underlying mechanism with the \gls{aitm}. For the reasons explained in section \ref{sec:invModel}, the special inverse model is used.

Algorithm \ref{alg:intUpdate} explains the steps that are performed each time new information is received from the environment.

\begin{algorithm}
	\KwIn{New worldstate ws}
	\KwIn{Used action a}
	\KwData{Last worldstate ws$_\text{old}$}
	\KwData{Set of Abstract Collections L}
	\KwData{Abstract Collection Selector ACS}
	\BlankLine
	\ForEach{interaction state i $\in$ ws}{
		i$_\text{old}$ = extractInteractionState(ws$_\text{old}$, i)
		newEpisode = Episode(i$_\text{old}$, a, i) \\
		$S$ = computeChangedFeatures(newEpisode) \\
		\tcc*[h]{Check if a corresponding AC already known} \\
		\If{$S$ $\notin$ L}{
			newAC = AbstractCollection($S$) \\
			L = L $\cup$ newAC 
		}
		AC = L$_S$ \tcc*[f]{The Abstract Collection responsible for $S$} \\
		update AC with newEpisode \\
		update ACS with i$_\text{old}$, a and AC
	}
	\caption{Prediction of the update steps in the pairwise interaction model.}
	\label{alg:intUpdate}
\end{algorithm}

The changed feature set $S$ is basically computed according to equation \ref{eq:difSet}\footnote{Since local features are used, both $Pre$ and $Post$ need to be transformed to the same coordinate frame, see section \ref{sec:episodes} for details.}. The structure and used features within the interaction state are explained in section \ref{sec:intFeatures} while the episodes are explained in section \ref{sec:episodes}.

When updating an Abstract Collection both its forward and inverse model need to be updated. The forward model as well as the inverse model are trained using the combination of the old interaction state i$_\text{old}$ and the action primitive a as input and the difference vector d between the old interaction state and the new one as desired output. The exact training of the \gls{aitm} is explained in section \ref{sec:ITM} while the training of the inverse model is explained in section \ref{sec:invModelRealization}.

The Abstract Collection Selector is trained on the same combination of i$_\text{old}$ and a as input, but it uses the identifier of the responsible Abstract Collection as desired output.
Since the selector also uses the \gls{aitm} as classifier, the exact update rules are explained below.

When used for the prediction the model follows the process visualized in figure \ref{fig:PairPrediction} and described in section \ref{sec:pairPrediction}.
Planning on the other hand is more complicated and requires additional knowledge about the features. While the general process follows what is explained in \ref{sec:pairPlanning}, the process of providing relevant interaction states as targets and extracting relevant action primitives from the returned preconditions is explained in section \ref{sec:pairPlanningReal}.


%The model itself only works on interaction states and action primitives. The specific structure and content of these features is explained in section \ref{sec:intFeatures}.


\subsection{Used features \label{sec:intFeatures}}

The pairwise interaction model basically only uses the interaction state and the action primitive vector as feature vectors. The actual composition of the interaction state depends on the objects that need to be represented. For this thesis, only simple objects are present in the scene which allows fairly simple interaction states as described in table \ref{tab:pairInteractionFeatures}.

\begin{table}
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill} } l l}
		\textbf{Feature} & \textbf{Description} \\ 
		\hline \hline 
		 Id 1 & Identifier of the reference object \\ 
		 Id 2 & Identifier of the second object \\ 
		 Local x Position & Local x position of the reference object \\
		 Local y Position & Local y position of the reference object \\
		 Local Orientation & Local orientation of the reference object \\
		 Relative x Position & Relative x position of the second object \\
		 Relative y Position & Relative y position of the second object \\
		 Relative Orientation & Relative orientation of the second object \\
		\hline 
	\end{tabular*} 
	\caption{This table shows exemplary features used to represent one interaction state. Relative positions and velocities refer to the coordinate system of the reference object.}
	\label{tab:pairInteractionFeatures}
\end{table}

Furthermore, the interaction state contains the information required for the transformations. Specifically, the matrix $T$ to transform from the local coordinate frame back to the global 
frame, its inverse $T^{-1}$ and the orientation of the reference object in the global coordinate frame.

The model assumes, that these interaction states come directly from the environment. Transformations from and to the actual object states need to be performed outside of the actual model. This is achieved by introducing a \textit{Worldstate}. From the point of view of the model, this world state is simply a collection of all interaction states in the environment. At each update from the environment, a new Worldstate is computed from the information provided. The model predicts a new Worldstate by making predictions about all interaction states that are included in a given Worldstate. Since one is usually more interested in the actual object states, the model finalizes the Worldstate after all interaction states have been predicted. This finalization extracts the object state predictions from the predicted interaction states. 

The interaction states are computed as follows:
In this case all features are computed by transforming the global features of both objects given by the environment to the local coordinate frame. Consider two objects $o_1$ and $o_2$ with positions $\vec{p}_1$ and $\vec{p}_2$ and orientations $\alpha_1$ and $\alpha_2$ respectively. First the transformation matrices $T$ and $T^{-1}$ are computed from the reference object's position and orientation:

\begin{equation}
T = \begin{pmatrix}
\cos(\alpha_1) & -\sin(\alpha_1) & px_1 \\
\sin(\alpha_) & \cos(\alpha_1) & py_1 \\
0.0 & 0.0 & 1.0
\end{pmatrix}
\qquad
T^{-1} = inv(T)
\label{eq:transMatrix}
\end{equation}

$px_1$, $py_1$ correspond to the $x$ and $y$ dimensions of the position $\vec{p}_1$. With the help of the transformation matrix $T^{-1}$ it is possible to compute the local positions, e.g.:

\begin{equation}
\vec{p}' = T^{-1} \times \vec{p_1}^*
\end{equation}

where $\vec{p}_1^*$ is the homogeneous vector of $\vec{p}_1$. Since $\vec{p}'$ is also in homogeneous coordinates, only the first two components are used for the interaction state. The local and relative orientations are computed by subtracting the orientation of the reference object from the given orientations. In fact by doing this, all local fields in the interaction state will be zero after the computation. However, these fields are still required. The Abstract Collections predict the change in the current interaction state. In order to extract the predicted object states from the interaction state, changes in the reference object need to be predicted as well. 

The object states are extracted by using the inverse transformation. Since the structure of the interaction states are known outside of the model, the predicted local position $\vec{q}$ can easily be extracted. Using the homogeneous coordinates $\vec{q}^*$ of $\vec{q}$, the prediction for the actual object's position $\vec{p}_{pred}$ can be computed:

\begin{equation}
\vec{p}_{pred}^* = T \times \vec{q}^*
\end{equation}

Velocities can be computed analog if needed.
In order to get the global orientation, the reference object's orientation simply needs to be added to the predicted orientation. 

\subsection{Episodes \label{sec:episodes}}

Episodes are used to store past experiences. The idea comes from case-based-reasoning \cite{cbr} where past experiences are used to reason about new problems. An episode is made up of three parts: 
\begin{enumerate}
\item The initial interaction state $Pre$ that was given before an action was performed.
\item The action that has been performed
\item The resulting interaction state $Post$ 
\end{enumerate}

As explained in the concept, these experiences can be stored and looked up at query time in order to make predictions. However, as highlighted before, the performance of such an operation deteriorates over time as the number of stored experiences increases. Instead, the Abstract Collections use these episode as training data for the local regression model. Apart from those three parts, all episodes compute a difference vector between the initial and resulting interaction state. 
However, since the model is working with local coordinates, it is important that both states are transferred to the same coordinate frame before computing the difference. As explained above, the features in all interaction states are always computed relative to the reference object's coordinate frame. As such the positional information of the reference object will always be zero in a freshly computed interaction state. This does however not mean, that the reference object has not moved within an episode. The model is interested in learning to predict how a given interaction state changes after a special action is performed. Therefore, the difference vector in an episode needs to represent the differences relative to the initial interaction state. This is achieved by first transforming the features of the $Post$ state back to global coordinates via $T_{Post}$ and then transforming them to the local coordinate frame of the $Pre$ state using $T^{-1}_{Pre}$. For the position of the reference object $p_{ref}$ (in homogeneous coordinates) this can be computed as follows:

\begin{equation}
\vec{p}'_{ref} = T^{-1}_{Pre} \times T_{Post} \times \vec{p}_{ref}
\end{equation}

When transforming the orientation of the $Post$ state, first the global orientation of $Post$'s reference object is added before subtracting $Pre$'s global orientation. All transformed features from $Post$ are again collected in a vector $Post^*$ where the features are organized in the same way as in a normal interaction state.

Afterwards the difference vector can simply be computed by:

\begin{equation}
\vec{d} = Post^* - Pre
\end{equation}

During training, the Abstract Collections extract the features differences they are responsible for from $\vec{d}$ and use those as target output of the local regression model.
Finally, the set of changing features $S$ can then again be computed as stated in equation \ref{eq:difSet} while substituting $Post$ for $Post^*$.

\subsection{From target object state to action primitives(?)\label{sec:pairPlanningReal}} %TODO change name

[Subject to change] %TODO finalize once program runs decent

In most cases the robot will have to push a certain object to a given specification. It usually does not matter where the actuator is after the target is reached. Therefore, it would be best if a target object state could be provided instead of a target interaction state. However, the model itself does not know about object states. Therefore, this prototype implements a method to convert a given object state to an interaction state, where only the reference object is set. The secondary object is the actuator however the actuator features are not required. Instead, the features representing the reference object are remembered in order to only focus on these features when trying to reduce the distance to the target interaction state. 

Once a target interaction state has been computed, the current interaction state between the reference object of interest and the actuator can be retrieved. Using the target interaction state as resulting state, an episode with an empty action is computed. The episode provides the difference vector between the current situation and the target configuration. Only the features remembered when constructing the target interaction states are considered from this difference vector. Effectively, these features correspond to the local differences in the object states. 

Using this reduced difference vector, the model tries to find the Abstract Collection that is responsible for changes in the features of interest. Since these features are only a subset of the entire interaction state, there will usually not be an Abstract Collection that is responsible exactly for these features. Instead there will be several Abstract Collections, that are responsible for these features as well as other features. 

Currently, all Abstract Collections, that also correspond to the features of interest, are queried for preconditions until valid preconditions are found. %TODO what are valid preconditions

Once preconditions have been retrieved from the inverse model, the current situation is compared to these preconditions. Most importantly, the current actuator position needs to be similar to the actuator position in the preconditions. This is checked by confirming that the signs in the relative positions are the same. The easiest way is to perform an element wise multiplication and check if any attribute goes below zero. If the actuator is indeed on the wrong side of the object, it needs to circle around the object. Unfortunately, this requires some world knowledge about the objects. In the given implementation, the user defined interaction states provide the ability to compute an action primitive that lets the actuator circle around the reference object at a fixed distance. 

When the actuator is already on the correct side of the object, it needs to reduce the distance to the position defined in the preconditions. This can be done by simply following the direction between the target position and the current position. 

Once the actuator has come close the position defined by the preconditions, the actual desired action primitive can be computed. The preconditions already contain local action primitives that were encountered during training. These can be transformed to the global coordinate frame using the transformation matrix $T$ from the current interaction state as described above. 

\section{Object space with gating function \label{sec:gateRealization}}

The realization consists mainly of the parts visualized in figure \ref{fig:GateOverview}. Depending on whether the actuator models are to be learned as well three to fife different parts need to trained in this model: The predictor takes on a similar role to the Abstract Collections in the previous model. For each distinct object group, a local forward model is trained using the relative interaction features (described in section \ref{sec:gateFeatures}) as input and the changes in the object states as output. Just as the interaction model, the inverse model is also trained on the same input and output data each time new information is available from the environment. 
%In this implementation, object groups are simply divided by the object identifier. %TODO consider this again after testing with 2 objects.
The gate trains a classifier in order to predict if an actuator object influences another object. The classifier is trained, using the relative interaction features as input. The output, i.e. if an interaction took place or not, is computed by computing the change between the previous object state and the current one.

Algorithm \ref{alg:gateUpdate} summarizes all steps performed at each update step.

\begin{algorithm}
	\KwIn{New worldstate ws}
	\KwIn{Used action a}
	\KwData{Last worldstate ws$_\text{old}$}
	\KwData{Predictor}
	\KwData{Gate}
	\BlankLine
	newActuator = extractActuator(ws) \\
	\ForEach{object state o $\in$ ws}{
		o$_\text{old}$ = extractObject(ws$_\text{old}$, o) \\
		relFeatures = computeRelativeFeatures(o, newActuator) \\ %TODO Check if this is correct for both gate and predictor or if this should be old actuator!!!
		change = computeLocalChange(o$_\text{old}$, o) \\
		hasChanged = $||$ change $||$ > 0 \\
		updateGate(relFeatures, hasChanged) \\
		\If{hasChanged}{
			updatePredictor(relFeatures, change) \\
		}
	}
	updateActuator(newActuator, a) \\
	\BlankLine
\caption{Algorithm summarizing the steps performed by the object state model at each update from the environment.}
\label{alg:gateUpdate}
\end{algorithm}

Extracting the actuator or an object state is simply an attribute lookup in the worldstate. The changes are computed by first transforming the new object state to the coordinate frame of the old object state before taking the difference of both vectors. 

When the object state has changed, the predictor is updated with the relative interaction features as input and the change as output. The predictor can determine the object by the identifier in the relative features in order to train only the local forward and inverse models responsible for the current object group.

Finally, the actuator is updated. This update trains the local forward and inverse model of the actuator, if no predefined ones were provided.
All update calls also update the information available in the last worldstate ws$_\text{old}$. Consequently, at the end of the update routine, the old world state and the current worldstate are identical.

When used to predict the next world state, the process visualized in figure \ref{fig:GatePrediction} and described in section \ref{sec:gatePrediction} is used for every object in the current world state. As mentioned in the concept, prediction is a sequential process in this model. First the next actuator state is predicted by querying its local forward model given the selected action primitive. The predicted actuator state is then used to compute the relative interaction features with the current object. This feature vector is then used to query both the gate and if required the object's local forward model in the predictor. The local models in the predictor do not know about the action primitives at all as a consequence of this sequential process. %TODO explain benefits of this

As in the other model, planning is more complicated and requires additional knowledge about the features. The steps required to extract useful action primitives towards a given target are explained in section \ref{sec:gatePlanningReal}


%Algorithm \ref{alg:gatePrediction} shows how a prediction for one object is performed. 
%
%
%\begin{algorithm}
%	\KwIn{Predicted actuator state from action primitive, object state}
%	\KwOut{Predicted object state}
%	\BlankLine
%	relFeature = computeRelativeFeatures(objectState, actuatorState)\\
%	\eIf{Gate(relFeatures)}{
%		predictedChange = getPrediction(relFeatures) \\
%		return add(objectState, predictedChange)
%		}{
%		return objectState
%		}	
%	\caption{Prediction pseudocode}
%	\label{alg:gatePrediction}
%\end{algorithm}
%
%The pseudo function \textit{getPrediction} first selects the responsible forward model before the change is predicted. This selection is being performed based on the identifier of the reference object. If no local model has been trained for the reference object, the predictor tries to find a forward model that is responsible for similar objects. If no suitable forward model can be found, a zero change prediction is returned. This means that the object state remains unchanged.


\subsection{Used features \label{sec:gateFeatures}}

Similar to the interaction model, this model also introduces a \textit{Worldstate}. This worldstate is also computed at each update from the environment. In this case, the worldstate simply collects the states of all objects in the environment. The actuator, although technically also an object, is regarded separately in the worldstate. Since the model directly predicts the new object states, no finalization is required. 
This model uses different kind of feature representations. The object states describe the specific features of each object and basically represent what is provided by the environment. The provided implementation can use dynamic features such as velocities, but does not require them. Table \ref{tab:gateObjectFeatures} summarizes the basic features that are used to represent object states.

\begin{table}
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill} } l l}
		\hline \textbf{Feature} & \textbf{Description} \\ 
		\hline \hline 
		 Id & Unique identifier of each object \\
		 x Position & Global x position in the environment \\ 
		 y Position & Global y position in the environment \\ 
		 Orientation & Object rotation around the z-axis of the global coordinate system \\ 
		\hline 
	\end{tabular*} 
	\caption{Table showing the different dynamic features used to represent objects.}
	\label{tab:gateObjectFeatures}
\end{table}

While additional information, such as information about the shape of the objects, is available, the object itself does not require it. However, when computing the relative interaction features, at least information about the shape is required. Furthermore, the model stores not only the current state of each object but also the previous one. This is required in order to make finite difference estimations about the objects dynamics such as velocity. In case the dynamics are directly provided by the environment, this previous state does not need to be stored. However, omitting the velocities and only estimating them when needed reduces the output dimensionality of the regression models. This is because the model predicts changes in all features that it experiences. Since the model does not have or require any knowledge about the features of the states for prediction, a selective prediction is not possible. Therefore, it is beneficial to reduce the number of features that need to be predicted. 

The different regression and classification models are trained using relative interaction features as input. As mentioned in the concept description, these features are similar to the interaction state described above. However, they do not need to represent the reference object since this model assumes, that the global configuration of the reference object does not influence the interaction. Therefore it is sufficient to model the actuator relative to the reference object, with additional information that might be useful for the learner.
The relative interaction features are summarized in table \ref{tab:gateInteractionFeatures}. 

\begin{table}
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill} } l l}
		\hline \textbf{Feature} & \textbf{Description} \\ 
		\hline \hline 
		 Id 1 & Identifier of the reference object \\ 
		 Id 2 & Identifier of the second object \\ 
		 Distance & Closest distance between the two objects \\
		 Closing & Describes how much the objects are moving towards each other \\
		 Relative x Position & Relative x position of the second object \\
		 Relative y Position & Relative y position of the second object \\
		 Relative x Velocity & Relative x velocity of the second object \\
		 Relative y Velocity & Relative y velocity of the second object \\
		\hline 
	\end{tabular*} 
	\caption{Table summarizing the different relative interaction features used to make predictions about interactions. Relative positions and velocities refer to the coordinate system of the reference object.}
	\label{tab:gateInteractionFeatures}
\end{table}

The \textit{Closing} feature $c$ is computed as described in equation \ref{eq:closing} and visualized in figure \ref{fig:closing}.

\begin{equation}
  c = \vec{n} \cdot \vec{rv}
 \label{eq:closing}
\end{equation}

where $\vec{n}$ represents the normal from the reference object towards the second object and $\vec{rv}$ represents the non normalized relative velocity vector of that second object. This equates to the cosine between these two vectors weighted by the magnitude of the relative velocity. This feature is minimal when the second object is moving directly towards the reference object. A positive closing value on the other hand indicates that the objects are moving away from each other. When the feature becomes 0 it indicates that the distance will not change. As mentioned above, the relative velocity is estimated by the finite difference of the current and last position.

The other relative features are computed by transforming their global counterparts to the coordinate system of the reference object. Equation \ref{eq:trans} shows this exemplary for the position:

\begin{equation}
	\vec{relPos} = T^{-1} \times \vec{gPos}
\label{eq:trans}
\end{equation}

where $T^{-1}$ is the transformation matrix computed from the reference objects orientation and global position as defined by equation \ref{eq:transMatrix}. $\vec{gPos}$ is the position vector of the second object in homogeneous coordinates. 

The distance is computed by computing the distances from all corners of one objects to all edges of the second object. %TODO
The distance between the two objects corresponds to the closest corner-edge distance. In case of round objects, such as the actuator, the center is considered as a corner and the radius is reduced from the computed distance.

\begin{figure}
	\centering
	\includegraphics[scale = 1.5]{closing.pdf}
	\caption{Visualization of the closing feature. The gray half circle shows the angle whose cosine is basically computed for the feature.} 
	\label{fig:closing}
\end{figure}

\subsection{From target object state to action primitive(?) \label{sec:gatePlanningReal}} %TODO change name
%TODO
[TODO]
The overall process of computing a suitable action primitive that allows push an object towards a given target configuration is quite similar to the one in the previous model explained in section \ref{sec:pairPlanningReal}. However, due to the differences in representation, the process is actually easier in this model. First of all, since the model works directly with the object states, the target representation does not need to be changed. Furthermore, finding the responsible local inverse model is a lot easier in this model due to the separation by object group instead of changing interaction features. 

The preconditions are received as visualized in figure \ref{fig:GatePlanning}: First the difference vector between the current object state and the target state is computed. Afterwards, the local inverse model responsible for the given object is queried for the preconditions given this difference vector. The actual computation of these preconditions is explained in section \ref{sec:invModelRealization}.

Once the preconditions have been computed, the same analysis as in the other model needs to be performed. These preconditions are in the form of the relative interaction features described above. Unlike in the prediction case, the model needs to have knowledge about what some of the features represent. Specifically, the information about the local actuator position $p_{cond}$ need to be extracted from these preconditions. Afterwards, $p_{cond}$ can be compared with the local actuator position $p_{cur}$, extracted from the current relative interaction features between the object and the actuator. If these two positions have the same signs in all attributes, the actuator is at least on the correct side of the object according to the preconditions. In this case the direction towards $p_{cond}$ can be used as action primitive in case the actuator is not close enough yet. Otherwise, the actual action primitive needs to be extracted from the preconditions. While the action primitives were directly included in the preconditions in the interaction model, the action primitives from training are not known to the inverse model here. However, the relative interaction features include the relative velocity of the actuator. In the given scenario, this velocity equates to the action primitive, since the action primitives control the velocities. The local velocities need to be transformed to the global coordinate frame, using the transformation matrix $T$ as explained above.

In the case that the actuator is not on the correct side of the object, a circling action is required. Unfortunately, this needs to be provided by the user since the model has no information about the shape of the objects or what circling means. In this implementation, each object state, that needs to be defined by the user anyways, provides a method that computes an action that circles the actuator around the object in a fixed distance. %TODO provide circling algo? in appendix?

\section{Used technologies \label{sec:technologies}}

\subsection{Time invariant inverse Model \label{sec:invModelRealization}} %TODO better name!

\begin{itemize}
\item Training
\item Averaging
\item structure
\end{itemize}

%TODO rework after moving here!!!

A prototype is trained for each direction of each feature that changed in the object state during an update. Each prototype computes a weighted average of the preconditions that resulted in a feature change represented by it. The preconditions are weighted by the magnitude of the change. 

Simply taking the average is however not possible as can be seen in figure \ref{fig:avgProblem}.

\begin{figure}
	\centering
	\includegraphics{avgProblem.pdf}
	\caption{Visualization of the averaging problem for point symmetric features. The circles represent the actuator while the rectangle represents a block object. Both pushing scenarios result in the same direction for orientation change of the object, however averaging the relative x and y positions would result in an invalid precondition.} 
	\label{fig:avgProblem}
\end{figure}

For point symmetric features, such as relative x and y positions in the figure, averaging results in invalid preconditions. In this case, the averaged preconditions would want the actuator to be in the center of the block, which is neither possible nor would it result in an orientation change. In order to prevent this, two averages are computed for each feature. One for all positive values of that feature and one for all negatives. on top of that, all combination of feature signs are stored and weighted by the magnitude of the change. When returning the entire preconditions, the averages corresponding to the sign combination with the highest weight are returned. Table \ref{tab:signCombinations} shows the combinations visible in the example above. In case combination 1 has the highest weight, the positive average for the x position, the negative average for the y position and the positive average for the y velocity is used. 

\begin{table}
	\centering
	\begin{tabular}{|c|c|c|}
		\hline Feature & Combination 1 & Combination 2 \\ 
		\hline x position & + & - \\ 
		\hline y position & - & + \\ 
		\hline y velocity & + & - \\ 
		\hline 
	\end{tabular} 
	\caption{Table showing the sign combinations for the example in figure \ref{fig:avgProblem}}
	\label{tab:signCombinations}
\end{table}

\subsection{Adapted instantaneous topological map \label{sec:ITM}}
%TODO Add pseudo code at the beginning to show general process or nice figure!
%TODO find better name! Consider calling it something closer to kNN since that is kind of what it becomes
The underlying regression and classification model that is used throughout this thesis is an adaptation of the \acrfull{itm} which will be called \acrfull{aitm} throughout this thesis.
The \gls{itm} \cite{itm} is an adaptation of the \gls{gng} \cite{gng} algorithm to create topological maps. Instead of \glspl{gng} global update rules for inserting new nodes in the map, the \gls{itm} uses local update rules in order to be better suited for correlated inputs. 
In order to be applicable to classification and regression, the \gls{itm} was further extended by an output function using the idea of \gls{llm} \cite{LLM}. In order to extend a topological map with an output function, each node represent the corresponding output vector $\vec{w}^i_{out}$ along its input vector $\vec{w}^i_{in}$. The \gls{llm} extends each node further with a local linear mapping $A^i$. This matrix is used to improve the function approximation within each Voronoi cell. With this, the output of each node given an input vector $\vec{x}$ is computed by equation \ref{eq:llmOut}:

\begin{equation}
\vec{y}^i(\vec{x}) = \vec{w}^i_{out} + A^i \cdot (\vec{x}-\vec{w}^i_{in})
\label{eq:llmOut}
\end{equation}

The output function for the net can be computed in multiple ways. The simplest method is to use the output of the winning node, i.e. the output of the node whose input vector $\vec{w}^i_{in}$ is closes to the given input $\vec{x}$. In order to reduce the effect of the metric problem when finding the closest node, the outputs of multiple nodes can also be mixed together. The evaluations in this thesis interpolate the output functions of the two closest nodes:

\begin{equation}
\vec{y}_{net}(\vec{x}) =  \frac{1}{k_n+k_s} \cdot \left[ k_n \cdot \left(\vec{w}^n_{out} + A^n \cdot \left(\vec{x}-\vec{w}^n_{in}\right)\right) + k_s \cdot  \left(\vec{w}^s_{out} + A^s \cdot \left(\vec{x}-\vec{w}^s_{in}\right)\right)\right]
\end{equation}

where $k_n$ and $k_s$ are the weights or importance for the nearest and the second node respectively. These weights are computed as follows:

\begin{equation}
\begin{split}
k_n = \exp\left(\frac{||\vec{x}-\vec{w}^n_{in}||}{\sigma^2}\right) \\
k_s = \exp\left(\frac{||\vec{x}-\vec{w}^s_{in}||}{\sigma^2}\right) 
\end{split}
\end{equation}

$\sigma$ determines the influence radius of each node, just like in radial basis networks \cite{rbf}. The nearest node $n$ and the second closest node $s$ are determined by comparing the input vectors of all nodes in $W$ with the given input vector $\vec{x}$:

\begin{equation}
\begin{split}
	nearest: n = \argmin_{c\in W} ||(\vec{x} - \vec{w}^c_{in})|| \\
	second: s = \argmin_{c\in W\backslash\{n\}} ||(\vec{x} - \vec{w}^c_{in})||
\end{split}
\label{eq:itmNearest}
\end{equation}

During training, the network receives an input-output pair and updates its nodes. First, the two closest nodes $nearest$ and $second$ are computed as stated in equation \ref{eq:itmNearest}. Afterwards, only the node $nearest$ is adapted:

\begin{equation}
\begin{split}
\Delta \vec{w}^n_{in} = \eta_{in} \cdot (\vec{x}^\alpha - \vec{w}^n_{in}) \\
\Delta \vec{w}^n_{out} = \eta_{out} \cdot (\vec{y}^\alpha - \vec{y}^n(\vec{x}^\alpha)) + A^n \cdot \delta \vec{w}^n_{in} \\
\Delta A^n = \eta_A \cdot (\vec{y}^\alpha - \vec{y}^n(\vec{x}^\alpha)) \frac{(\vec{x}^\alpha - \vec{w}^n_{in})^t}{||\vec{x}^\alpha - \vec{w}^n_{in}||^2}
\end{split}
\end{equation}

The initial matrix $A$ is a zero matrix with proper dimensions. The learning rates $\eta_{in}, \eta_{out}$ and $\eta_A$ are meta parameter that need to be determined. In case $\eta_A$ is set to 0, no linear approximation is learned for each Voronoi cell. This means, that each cell has only the constant output of $\vec{w}^n_{out}$.

After the winning node has been updated, the classical \gls{itm} algorithm uses local relations between the new input, the winning node and the second node in order to determine if a new node should be inserted or if some node should be deleted. As long as there are no big jumps in consecutive training samples, this approach works quite well. However, when resetting the environment between consecutive training runs, larger gabs can arise. Furthermore, this network has already been extended by an output function which can now also be used during training. This adapted \gls{itm} inserts new nodes into the network if the current network output varies too much from the target output, i.e if:

\begin{equation}
||\vec{y}^{net}(\vec{x}^\alpha)-\vec{y}^\alpha|| > \epsilon_{ITM}
\end{equation}

The threshold $\epsilon_{ITM} = 10^d$ is dynamically computed, based on the order of magnitude $d$ of the target output norm: %TODO example

\begin{equation}
d = \begin{cases}
\lfloor\log_{10}(||\vec{y}^\alpha||)\rfloor-1 & \text{if $||\vec{y}^\alpha|| > 0$} \\
-k & \text{otherwise}
\end{cases}
\end{equation}

When the output has a norm of $0$ a fixed threshold $10^k$ is chosen. Ideally $k$ should represent the average order of magnitude of the input. This average can be computed incrementally from the non-zero output norms. The benefit of such a dynamic threshold is that it automatically adapts to different use cases. For example, when the \gls{aitm} is used for classification, the output values will be class labels in the form of positive natural numbers. In this case $d=0$ which results in a threshold of 1. In regression tasks however, the output values will be real numbers. It is obvious that different thresholds are required for both types of use case. The \gls{aitm} assumes that the orders of magnitude of the output within one use case are generally rather similar and can be used as an approximation of the desired accuracy.

%TODO Subject to change
With every update the two winning nodes are connected as neighbors. Node deletions are performed just as in the traditional \gls{itm}: Second winners are removed if they are too far away from the winning node. Furthermore, isolated nodes will be deleted. A node is considered isolated if it does not have any neighbors left. Neighbor connections are removed if the second winner in an update can replace a previous neighbor:

\begin{equation}
\forall c \in N(n): \text{If~} (\vec{w}^n_{in}-\vec{w}^s_{in}) \cdot (\vec{w}^c_{in}-\vec{w}^s_{in}) < 0 \text{~remove connection (n,c)}
\end{equation}

$N$ denotes the set of neighbors of the winning node $n$.

%\subsection{Abstract inverse model}
%%TODO
%[TOOD maybe move description from concept here]
