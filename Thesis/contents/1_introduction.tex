\chapter{Introduction}

%Motivate necessity
%State goals
%Structure of thesis
%What is the problem that we try to solve?
%Why is it relevant to solve it?


%TODO delete? Most likely not good...
%The defining quality that any agent, artificial or natural, requires is learning. Also used for many different 
%phenomenons, the term learning at its core means adaptation. The agent or some part of it adapts in order to
%better deal with its environment. Natural agents, especially humans, display impressive learning capabilities,
%allowing them to quickly adapt to ever changing environments and new tasks.
%
%In recent years, machine learning has come a long way in understanding and reproducing some of the learning
%capabilities of humans. We now have a wide range of different techniques and algorithms that can yield good
%classification and regression results. %TODO make glossary to explain what classification and regression is
%In introduction to these can for example be found in book by Bishop \cite{bishop}.
%
%The quality of the results achieved by machine learning is however more dependent on the chosen representation
%of the problem then on the actual technique used. For example it is generally not sufficient to use the raw audio signals 
%for speech recognition \cite{speechRecog}. Instead most speech recognizers use carefully selected pre-computed
%features that allow the underlying machine learner to correctly distinguish the words. 
%
%Because finding the best features is as challenging as learning a problem itself, a lot of focus as recently 
%shifted to deep learning \cite{deepLearning}. Deep learning is a technique that is inspired by the human brain and refers to
%training neural networks with many thousands of artificial neurons. Properly trained, these networks are capable of finding 
%relevant features in the presented data by themselves \cite{deepLearningFeatures}. Currently the biggest
%problem with deep learning is the required amount of training before the network can be used successfully. Although recent
%advances such as the development of Hinton's dropout technique \cite{dropout} allows to train bigger networks with fewer data,
%this criteria still limits the potential use cases of deep learning and neural networks in general.
%TODO maybe one paragraph more towards the topic of this thesis?
After decades of research a vast amount of powerful tools have been developed for machine learning. Each of these methods has its own advantages and disadvantages and are applicable to certain situations. Currently, research in machine learning is often performed by choosing a problem, e.g. image recognition or movement control, and trying to find and tune the most successful method to solve the chosen problem. This includes fine tuning the features that are used to represent the given data. This way the researchers were able to create better classifiers for image recognition (e.g. \cite{imageRecList}) and better controllers for complex movements (e.g.\cite{movementList}). A good overview over different machine learning approaches can be found in the book by Bishop \cite{bishop2006pattern}.

In most of these cases the machine is trained to solve one specific problem. Depending on the chosen methods it is not possible to extend the machines knowledge easily without retraining the entire system afterwards because of the stability-plasticity-problem \cite{stability-plasticity}. More precisely because of the phenomenon of catastrophic forgetting\footnote{The phenomenon of forgetting previously learned information after receiving new information. Most prominent in neural networks and when trying to learn non-stationary data.} \cite{catastrophicForgetting1}.

In recent years, deep learning \cite{deepLearning2009,deepFrontier} has attracted a lot of attention by achieving great results in high dimensional classification tasks such as image classification \cite{deepImageClassification}. The ability of deep learning approaches to automatically extract relevant features from high dimensional data, is one of the main reasons for the strong interest. However, so far deep learning requires a lot of training data to be successful which is why it is not further considered in this thesis.
%TODO mention deep learning

With advances in robotic hardware and the successful application of machine learning in specialized tasks, such as image recognition, the goal of robotic research trends towards multi-purpose robots. However, the biggest problem for multi-purpose machines is that the current approach to machine learning is not applicable. Since the number of tasks the robot has to face is not known in advance, it is difficult to train suitable tools beforehand. Furthermore, even if one would attempt to train specialized parts for all kinds of problems, acquiring sufficient and accurate training data beforehand is infeasible at best. On top of that, robotic platforms often only have limited computational resources which limits the amount of data they can process at once.
%TODO glossary for model or some footnode on what is meant by model
Therefore, instead of trying to train the machine beforehand, it might be better to provide the robot with the means to adapt to new situations on its own while it is encountering them. 
Instead of learning a complete model\footnote{A model represents the robot's knowledge about the world.} on previously recorded training data, the robot adapts its model to the continuous stream of data while it is already using what it has learned so far. 
The biggest reason against such an continuous incremental approach is its difficulty. When incrementally training a single model to solve multiple different problems, the catastrophic forgetting effect is often experienced. Furthermore, different kind of tasks may require different features which makes training a single model infeasible. The usual approach is to learn local models for each task separately, however this introduces the need to recognize and distinguish the different problems in order to know which kind of local model the robot needs to employ.

Instead of challenging the entire problem of incrementally learning an unlimited number of arbitrary tasks, this thesis concentrates on the incremental learning of one task without prior training. 
While there are multiple machine learning methods that allow incremental updates, not all of them are suitable for this kind of task. 
First of all, the method should be as independent on prior knowledge or the used features as possible so that it can be used for a wide variety of task the robot might encounter. Furthermore, the update and query times of the chosen method need to be quick enough to allow continuous interaction with the environment. On top of that, the chosen method should not suffer from the catastrophic forgetting effect since the robot would constantly keep updating its model. Memory based approaches, such as \gls{gng} have already been successfully used in robotic scenarios \cite{carlevarino2000incremental}. Due to their one-shot learning ability, memory based methods can produce good prediction results from very little training data. It is for these reasons, that this thesis also focuses on a memory based approach. 

One important aspect of general purpose robotics is object manipulation. In order to successfully interact with the objects in its environment the robot needs to learn what kind of interactions are possible and what their effects are. 
Furthermore, object interactions are hard to model manually as they follow complex dynamics. On top of that, different object can behave completely differently, so that knowledge acquired in previous training sessions might not be useful later on. It is for these reasons that object interactions make an ideal target for online self adaptation. 

This thesis presents and compares two concepts that provide incremental learning of pushing interactions between an actuator\footnote{The part of a robot that acts upon its environment.} controlled by action primitives and some object in the environment.
While pushing interactions are only a very small subset of possible interactions a robot can have with objects, their dynamics still provide sufficient complexity to evaluate incremental learning systems. Since the behavior of differently shaped objects can vary a lot, learning about different kind of objects can even be regarded as learning similar but different tasks.%TODO Maybe more on this?
The proposed concepts need to provide a forward model as well as an inverse model. The forward model makes predictions about the state of all entities in the environment after an action primitive has been performed. The inverse model provides an action primitive that is used to reach a specified target configuration within the environment.
%Both models should to allow continuous updates without a deterioration in their performance.

The goal of this thesis can be summarized to provide and evaluate simple models that:
%TODO planning and lifelong are mentioned here for the first time and not explained!!!
\begin{enumerate}
	\item Update themselves incrementally during the interaction
	\item Allow prediction of simple object interactions % with minimal domain knowledge
	\item Allow the deduction of action primitives required to reach a given target 
\end{enumerate}

%TODO Anmerkung Jacqui: Kein schöner Übergang zum vorherigen
This thesis is structured as follows: In chapter \ref{chap:stateOfTheArt} an overview on memory based learning as well as recently proposed models for learning object interactions for robotics is given. Two concepts were developed in order to fulfill the stated goals. Their general idea is described in chapter \ref{chap:concept} before concrete implementation details are given in chapter \ref{chap:modelReal}. These models are then evaluated with regards to the goal mentioned above in chapter \ref{chap:evaluation}. These results are discussed in chapter \ref{chap:discussion} before concluding this thesis in chapter \ref{chap:conclusion}.

