\chapter{Evaluation\label{chap:evaluation}}


%Explain simulation and communication
%Evaluate different models task based
%How where the realisations/ideas tested?
%What were the results of those tests?

The implementations of the developed concepts were evaluated with regard to the three requirements stated in the introduction: 
\begin{itemize}
\item Update models incrementally during the interaction
\item Prediction of future object states
\item Incrementally reach a given target configuration
\end{itemize}

In order to evaluate these requirements, the implementations are tested in two different tasks using a physics simulation. The first task, the \textit{Push Task Simulation} tests the forward models of the different implementations. The actual task as well as the results achieved in that task are explained in section \ref{sec:pushTaskSim}.
The second task, \textit{Move to Target}, tests the implementations' ability to move an object towards a given configuration. This task and its results are explained in section \ref{sec:moveToTarget}.
Both tasks are evaluated using different settings for the implementations.

The used simulation software as well as the simulated environment are explained in section \ref{sec:environment}.


\section{Simulation and environment \label{sec:environment}}

The model is supposed to learn object manipulation through interaction.
The developed prototype implementations are tested in a simplified simulation. For this work gazebo \cite{gazebo} version 2.2.3 was used with the physics engine Open Dynamics Engine (ODE) \cite{ode}.
Gazebo simulates physics one step at a time at fixed time intervals. It is possible to configure the maximum step size for each update step as well as the number of steps to be performed in one second in real time. 
The simulation time depends on these to values. For this thesis, the standard step size of 0.001 simulation seconds is used. The \enquote{real time update rate}, which determines how many steps are performed in one second in real time, is used to control the speed at which the simulation is performed. 
This thesis uses an update rate of 500 when the models are to be updated at 100Hz according to simulation time. By setting the update rate to that half of real time, the models have 0.02 seconds in real time in order to finish their updates and queries. %TODO consider redoing or moving elsewhere
The simulation sends information about the objects every x steps, where x depends on the chosen update rate and step size. When using 100Hz, the simulation publishes the objects' information every 10 steps.

A very simple two dimensional environment is used, only containing a spherical actuator and a rectangular cube object that can be seen in figure \ref{fig:gazeboWorld}.
The used action primitives were chosen based on their ease of implementation in the simulation, since it is quite easy to change the global velocity of an object
at runtime. For simplicity the spherical actuator's orientation is fixed to 0 so that the global velocities always correspond to the local coordinate system of the actuator.

The dimensions of all objects as well as their friction coefficients used by the physics simulation are listed in table \ref{tab:environmentObjects}.
The fairly high friction coefficient for the block was chosen in order to better suit the assumption of the object state model. By increasing the friction the block will slide less. 

\begin{table}
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill} } c c c c}
			\hline \textbf{Object} & \textbf{Dimension} & \multicolumn{2}{c}{\textbf{Friction coefficients}} \\ 
			\multicolumn{2}{c}{} & $\mu_1$ & $\mu_2$ \\
			\hline \hline 
			 Actuator & $0.025m$ & 0.01 & 0.01 \\
			 Blue rectangular cube & $0.5m \times 0.1m \times 0.1m$ & 0.9 & 0.9 \\  
			\hline 
	\end{tabular*} 
	\caption{Table summarizing the dimensions and friction coefficients for the objects in the environment. If only one dimension is given, it represents the radius. Three dimensions correspond to the width, depth and height of an object.}
	\label{tab:environmentObjects}
\end{table}

\begin{figure} 
	\centering
	\includegraphics[width=10cm]{gazeboWorld.png} 
	\caption{Overview of the used environment. The black sphere represents the actuator, the models can control using action primitives. The blue square represents the object that the actuator interacts with.}
	\label{fig:gazeboWorld}
\end{figure}


\subsection{Communication}
Gazebo uses a client-server architecture. The actual simulation is being performed by the server.
This server publishes Google Protobuf \cite{protobuf} messages via TCP/IP. Interested clients, for example a graphical user interface, can register themselves as listener to messages of desired types. 
It is also possible to send messages to the server in order to influence the simulation. 

The server can furthermore be extended by writing custom plug-ins that handle self defined messages or perform some sort of additional computation at each update step of the simulation. 

In order for the Python prototypes to communicate with the simulation, an interface on both sides was created.

On the side of the simulation, a custom server plug-in was written, that publishes the information described in table \ref{tab:availInformation} in the realization chapter. 
The server publishes the 
The information for all objects is packed into a custom Protobuf message, which is explained in details in Appendix \ref{sec:protobufMessages}. Basically, this message simply contains a list of object descriptions where each object description contains the information explained in table \ref{tab:availInformation}.
Furthermore, the plug-in receives custom control messages. These messages allow the Python interface to influence the simulation.
While the exact messages are explained in the Appendix \ref{sec:protobufMessages}, table \ref{tab:commands} gives an overview about the possible commands, that can be send to the simulation.

On the Python side, an interface was written with the help of the module pygazebo \cite{pygazebo}, which provides Python bindings for the message passing system used by gazebo. This interface handles the messages that are received from and send to the simulation. 
The simulation sends information about the objects at a fixed rate. At each update step, the interface performs four to five actions:
\begin{enumerate}
\item Construct a suitable worldstate from the provided information
\item Get a prediction about the next worldstate from the model using the current worldstate
\item Update the model with the current worldstate
\item Get an action primitive from the model given a target configuration
\item Send the current action primitive to the simulation
\end{enumerate}

The 4th step is only performed in the tasks evaluating the inverse model. In the \textit{Push Task Simulation} a fixed action primitive is predetermined.

Furthermore, the Python interface provides the testing framework of setting up the models and managing training and testing runs as explained in detail below.

\begin{table}
	\centering
	\begin{tabular}{|c|c|}
		\hline \textbf{Command} & \textbf{Meaning} \\ 
		\hline Move Command & Sets the velocity for the actuator \\ 
		\hline Pause & Pauses the simulation \\
		\hline Continue & Continues the simulation \\
		\hline Reset & Resets the world to starting configuration \\
		\hline Set Pose & Places a specified object at a certain position \\
		\hline
	\end{tabular} 
	\caption{Overview of all implemented commands to influence the simulation.}
	\label{tab:commands}
\end{table}

\subsection{Sources of noise}

Although the object's attributes can be read accurately from the simulation, some random noise is still present in the data: \\
1) The physics simulation and the sensors that record the object's attribute are run in different threads within
in the simulation. These threads cannot always be perfectly synchronized which can result in minor differences in consecutive 
timesteps. \\
2) The physics simulation itself might encounter numerical instabilities, especially when computing resting forces. These instabilities
might lead to small oscillations within an object's features, such as position. In order to filter out such small noise, all
information from the simulation is rounded to 3 decimal places while constructing the worldstate. \\
3) The strongest variation comes from the fact that the implementation communicates with the simulation via asynchronous messages. 
All runs start in a configuration where all objects are resting. In the very first update step, the Python interface sends the first
action primitive to the simulation, which results in the actuator moving. The exact time when the simulation retrieves and executes
the action is however not deterministic. Depending on the system's load the simulation might have already performed 5 update steps before
it receives and executes the action. In this case, the action affects only half of the update steps. In another situation, the action might
be executed earlier. From the model's point of view, the same action was performed from the same initial situation, but the results can
differ greatly. 

Since this thesis considers a rather simple scenario and these three sources of noise are already present due to the used technologies,
no additional artificial noise was introduced to the system.

\section{Push Task Simulation \label{sec:pushTaskSim}}

The \textit{Push Task Simulation} is designed to test the accuracy of the forward model of both concepts. 

\subsection{Scenario description}

In this task, the actuator uses a constant action primitive in order to first move towards the block and then push it.
In order to evaluate different interactions, the actuator starts at different starting positions on a line parallel to the block. 

The distance between the starting line and the center block is 25cm. With the used speed, the actuator reaches the block in about 35 update steps after the start of a run. Depending on the third issue explained above, this number can vary a little.

After a 150 update steps, a \textit{run} ends and the object's are reset. This means, that the block will be placed at its resting position and the actuator is moved back to the starting line. 

During a run, the block status can change in a number of ways. In case the actuator goes past the block, it will not change at all. If it is pushed in the center, it will be translated up to 0.6m. Furthermore, depending on where the block is pushed, it will be rotated up to 1.02rad (around 58°) in either direction. The maximum rotation is experienced when the actuator starts around 0.105m away from the origin.

An example starting and end configuration can be seen in figure \ref{fig:pushTaskSim}. 

As the name suggest, this task is designed to evaluate the prediction performance of the models during the pushing interaction. The \enquote{simulation} part of the name comes from the fact, that the models will make consecutive predictions based on their last prediction. At the start of each run, the models will make their first prediction based on the current worldstate provided by the simulation. This prediction is then used to construct an appropriate next worldstate which is used at the next update step from the simulation.
Furthermore, the predicted states of both the actuator and the object are send to the simulation for visualization as can be seen in figure \ref{fig:pushTaskSim}.

The models will not get any feedback from the real environment in this setting, which means that they will not be able to adapt their predictions based on the actual interaction. 

In order to be able to make predictions at all, the model will first perform a number of training runs. During these training runs, the models are provided with the current worldstate from the simulation in order to train their local models.

In all runs, an action primitive is used that sets the velocity of the actuator to 0.5m/s straight upwards. Although only a constant global action is used, the prediction task is still challenging enough: \\
The constant action primitive does make it easy for the object state concept to learn the forward model of the actuator. However, the local forward model for the object is not as simple because the velocity is not constant in local coordinates but rather depends on the object's orientation. 
Similarly, in the interaction concept, the used action primitive is also transformed to local coordinate frame of the reference object.

Different kinds of training scenarios are evaluated in this task which are further explained below when their results are presented.


\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{PushTaskSim.png}
	\caption{Exemplary start and end configuration of a \textit{Push Task Simulation} run. The left side shows the start configuration, while on the right the corresponding end configuration can be seen.
		The darker objects (dark blue and black) represent the actual block and actuator, while the transparent objects symbolize the predicted objects.}
	\label{fig:pushTaskSim}
\end{figure}


\subsection{Evaluation criteria}

This task tries to evaluate the precision of the different models. In order to measure this precision, the distance between the predicted object state and the actual object state is computed at the end of each test run.
In this scenario, the models predict up to two quantities: The position and the orientation. 

As already mentioned before, finding a metric that can adequately combine difference in position and orientation at the same time is difficult. Furthermore, the interpretation of such a measurement is not intuitive. Therefore, the differences in position and orientation are considered separately. 
The positional difference is computed by the euclidean distance between the centers of the predicted and the actual object. The difference in orientation is given by the absolute difference between the predicted and the actual orientation.

Each training and testing setting is repeated 20 times and the average differences in position and orientation as well as their standard deviations are recorded. 

\subsection{Evaluated configurations}
%TODO
The implementations of both concepts offer several possible configurations, beginning by using different features, to using hard coded components in the gating concept.

In this evaluation, the implementations are evaluated first in the configuration described in the last chapter with meta parameters chosen as indicated by table \ref{tab:parameters}

\begin{table}
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} c c }
			\hline \textbf{Name} & \textbf{Configuration detail}  \\ 
			\hline \hline 
			 Interaction &  \\
			 Gate &  \\  
			\hline 
	\end{tabular*} 
	\caption{Table summarizing the meta parameters used for the presented evaluations.}
	\label{tab:parameters}
\end{table}

Apart from this basic configuration, both models are evaluated when they only use a subset of all features for the Abstract Collection Selector and the gating function respectively.

The features used for the Abstract Collection model correspond to the local actuator position, while the gating function is trained only on the distance and the closing feature.
All other meta parameters remain identical.

These configurations are used in order to evaluate the effect of unnormalized features in the memory based classifiers. %TODO weiter ausführen.


\subsection{Results}

%TODO Also test only interaction prediction performance, by removing all the instances where only the gripper moved!

The first test evaluates the prediction accuracy against the number of training runs. The training run start positions were chosen at random in the range of -0.25m to 0.25m. This means that they span the entire width of the block objects.
For each number of training runs that was evaluated, 21 test runs were performed where all positions from -0.35m to 0.35m at 0.035m intervals. This means that 4 test runs went past the object without interacting with it.
The averaged results for the block predictions over all folds for the interaction state model can be seen in figure \ref{fig:learnCurveInteraction}.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{LearningCurveinteractionModel_C_0_ERestACS.pdf}
\caption{Learning curve for the interaction concept. Difference in position and orientation for the block predictions at the end of a run are shown. Error bars indicate one standard deviation.}
\label{fig:learnCurveInteraction}
\end{figure}

The positional prediction error starts around 0.26m with a standard deviation of around 0.16m when the model is only trained with a single training example. The prediction performance improves to roughly 0.08m with a standard deviation of around 0.04m.
The predicted orientation error starts at an average of about 0.82rad with standard deviation of 0.32rad but improves to around 0.26rad with standard deviation of 0.09rad when increasing the number of random training examples.
The performances for position and orientation do not increase much more when training on 30 runs instead of 20. (0.10m $+/-$ 0.05m for position after 20 runs and 0.28rad $+/-$ 0.11rad for orientation).

The results for the same experiment with the object state with gating function model are presented in figure \ref{fig:learnCurveGate}.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{LearningCurvegateModel_C_0.pdf}
\caption{Learning curve for the object state with gating function concept. Difference in position and orientation for the block predictions at the end of a run are shown. Error bars indicate one standard deviation.}
\label{fig:learnCurveGate}
\end{figure}

The positional prediction error starts at around 0.16m with a standard deviation of 0.1m for only one training run in the object state with gating function model. By increasing the number of random training runs to 30, the positional error reduces continuously to around 0.04m with standard deviation of only around 0.02m.
The predicted orientation error starts at around 0.46rad with standard deviation of 0.29rad.
After 30 test runs an error of 0.13rad with a standard deviation of 0.08rad remains.
For this model the performance does not increase much more already after having seen only 5 training runs for both the error in position (0.06m $+/-$ 0.03m) as well as orientation (0.18rad $+/-$ 0.10rad).

The worse performance of the interaction model can partly be attributed to the test runs that do not interact with the block. While the gating function successfully learns to predict when an interaction takes place, the Abstract Collection Selector of the interaction model chooses \glspl{ac} where the block is moved even in situations where the actuator goes past the block.

[TODO evaluation of only interaction test positions!]
\begin{itemize}
\item Only interaction test positions
\item Actuator positional error
\item Second configuration!
\end{itemize}

\textbf{Generalization details:}

In order to analyze the information required for generalization, another training scheme was used. This time the models were only provided with three predetermined training runs. The starting positions -0.18m, 0.0m and 0.18m were used in this experiment. These three were chosen in order to provide the models with examples of both possible rotations as well as the lateral movement. The same 21 test runs were performed as before. This time prediction errors at the end of the run are recorded for each starting position separately. Due to the noise explained above, some randomness is still present in the data which is why this experiment was also repeated 20 times. 

The results for the interaction model are shown in figure \ref{fig:eachPosInteraction}.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{EachPosinteractionModel_C_8.pdf}
\caption{Prediction error for the interaction model at each of the 21 test positions after seeing three exemplary training examples. The training positions are highlighted by the block lines. Error bars indicate one standard deviation.}
\label{fig:eachPosInteraction}
\end{figure}

%TODO fill inserts here!
As mentioned in the previous setting, the predictions for the test runs that do not actually interact with the block, are rather bad. The model predicts a change in position around [insert here ] and in orientation around [insert here] on both sides of the object. 
For the test runs where the actuator actually moves the block, the prediction is a lot better. It is quite good close to the seen training examples: The positional error is as low as [insert here ] around the two outer training positions and slightly higher for the central position ([insert here]). Generally the same applies for orientation, but the central position now has a prediction error for orientation of 0, while the outer positions are slightly higher ([insert here]).
The further away from the training positions, the worse the prediction for both position and orientation becomes. Interestingly, the worst positional prediction of [insert here] happens 0.105m away from the center, while the worst prediction for orientation of [insert here] is seen 0.07m away from the center.
It is also interesting to note, that the orientation is predicted very consistently (all standard deviations below [insert here]), while there is slight variance in the positional predictions (standard deviations around [insert here]), despite the fixed training and test set.

The results for the same experiment performed with the object state model are presented in figure \ref{fig:eachPosGate}

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{EachPosgateModel_C_8EGateF23.pdf}
\caption{Prediction error for the object state model at each of the 21 test positions after seeing three exemplary training examples. The training positions are highlighted by the block lines. Error bars indicate one standard deviation.}
\label{fig:eachPosGate}
\end{figure}

%TODO fill inserts
The object state with gating function successfully does not make predictions for the test runs that go past the object after seeing the three fixed training runs. For the test positions that actually interact with the block, the predictions are better for positions close to the training examples. %TODO finish

[Explanation of figure \ref{fig:eachPosGate} ]

%TODO
[TODO]
\begin{itemize}
\item Image sequence of a test
\item PushTaskSimulation2
\end{itemize}


\section{Move to Target \label{sec:moveToTarget}}

The \textit{Move to Target} task is designed to evaluate the concept's ability to reach a given target configuration incrementally. 

\subsection{Scenario description}

In this task only a target configuration for the block object is given to the models. At each update step the models are updated with the current worldstate.
This means that they can adapt their inverse model during testing.
Afterwards, the interface queries the model for the next action that is then send to the simulation. This is repeated until the target configuration is reached or a maximum number of steps of 1000 %TODO check
has been performed.

The models are first trained on a fixed set of training runs. The set is designed to show important interactions to the models before testing.

The train runs are performed by placing the actuator in a suitable starting position before applying a constant action primitive directed towards the block.
The used action primitives all have a norm of 0.5m/s.

After training, both the actuator and the block are returned to their initial position. The block is located 0.25m above the global origin without any rotation, while the actuator is placed directly on top of the global origin.
Figure \ref{fig:moveToTargetScenario} visualizes the situation where the actuator just starts moving after training.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{MoveToTargetScenario.png}
\caption{Visualization of the \textit{Move to Target} task after training. The transparent light blue block indicates the desired target configuration. The blocks have been marked with the black corner to distinguish their orientation.}
\label{fig:moveToTargetScenario}
\end{figure}

\subsection{Evaluation criteria}

The performance of the inverse model is measured by the number of actions required to reach the target. If the target has not been reached within the allowed number of steps, the remaining difference is recorded. Similar to the previous task, position and orientation differences are recorded separately.

While recording the number of required steps, actual interactions where the block is moved and steps where only the actuator moves are distinguished.

Furthermore, the average change in position and orientation per performed action is recorded in order to judge the quality of the selected action primitives.

\subsection{Results}
%TODO
[TODO]

\begin{itemize}
\item Table for 
\end{itemize}

\begin{table}
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} c c c c c c c c}
			\hline \textbf{Concept} & \textbf{Target reached} & \textbf{Remaining position} & \textbf{Remaining orientation} & \textbf{\# steps} & \textbf{\# interaction steps} & \textbf{Avg position} & \textbf{Avg orientation} \\ 
			\hline \hline 
			 Interaction &  & & & & & & \\
			 Gate & & & & & & &  \\  
			\hline 
	\end{tabular*} 
	\caption{Table summarizing the dimensions and friction coefficients for the objects in the environment. If only one dimension is given, it represents the radius. Three dimensions correspond to the width, depth and height of an object.}
	\label{tab:moveToTargetResults}
\end{table}