\chapter{Discussion \label{chap:discussion}}

%TODO text here??
\section{Generalization performance}

The first task was designed to evaluate the generalization capabilities of the memory based concepts. It is important to note, that no domain knowledge outside the stated assumptions was provided to either model for this prediction task. Although the used features were selected by hand, no preprocessing of these features is performed and no knowledge about special feature dimensions is provided. It is highly likely, that the generalization performance of both models could be increased by providing fine tuned distance metrics and/or preprocessing the used features.
However, such knowledge is usually not available to the machine when encountering novel situations which is why such optimizations were not considered here.

\subsection{Generalization on random training data}

Prediction performances of both models reach acceptable levels for position and orientation considering 150 timesteps are predicted without correction. 
Both models prediction for the blocks position are on average less then 10cm incorrect after having seen 30 random training runs. The models predict the rotation of the objects correct up to an average error of around 15° for the interaction, and less then 6° for the object state model.

Overall, the object state model outperforms the interaction state model by requiring less training runs while achieving better prediction results as soon as at least 2 training runs have been seen.
%This holds true for both tested configurations as can be seen when comparing figures \ref{fig:learnCurveGate1} and \ref{fig:learnCurveInteraction1}. 
%TODO check if really for both configurations
This performance difference is most likely due to the higher complexity of the Abstract Case Selector compared to the gating function. While the gating function only needs to learn a binary classifier, the Abstract Case Selector, needs to choose from a potentially big number of possible local models. Choosing an incorrect model results in a poor prediction, which will be accumulated over the course of the test run. Furthermore, the gating function is provided with more information than the Abstract Case Selector, due to the features distance and closing, that are introduced in the relative interaction features. 

The better performance of the interaction model after just one training run, is most likely due to the fact, that the gating function needs at least two runs before it works sufficiently well. If the gating function performs poorly, an incorrect choice by the Abstract Case Selector might still result in a better prediction than predicting no change at all.

The worse performance in predicting the actuator position of the interaction model was expected and is due to the problem of dependency within an interaction state, as already mentioned in section \ref{sec:interactionTheory}. In that model, the actuator is not predicted directly, but only in combination with the block. That way the actuator's prediction is not only inaccurate if the regression model is not sufficiently trained, but also when the Abstract Collection Selector chooses an incorrect \gls{ac}. The dedicated regression model in the object state concept does not suffer from these problems and can learn the direct relation between action primitive and change in actuator state. The good prediction performance of the dedicated regression model indicates that the \gls{aitm} is capable of filtering out most of the noise generated by the setup. The reason for that is, that despite not using learning rates, the an existing winning node is adapted if it's output was incorrect despite being close to the new input data. 

However, the dedicated regression model for the object state concept does come at the cost of additional constraints on the model in the form, that the actuator needs to be specified explicitly. While most robots should have some knowledge about their actuators, this introduces another dependency that the interaction concept does not require.

\subsection{Generalization on selected training data}

The evaluations with selected training runs highlight to what extend the proposed models are capable of generalization. Obviously for memory based approaches, the best performance is achieved close to the known positions. However, despite not having seen the situations with the biggest change in orientation, the models are able to interpolate to some extend as can be seen in figure \ref{fig:EachPosEndPos}.

Overall the object state model performs better than the interaction model, which is most likely attributed to the already mentioned complexity discrepancy between the gating function and the Abstract Collection Selector. 
However, around the edges of the object, the interaction model makes better predictions about the orientation. It turns out, that the object state model does not make predictions for the outer testing positions. In this case, the gating function is not sufficiently trained with the provided data.
Despite that, the gating function is able to generalize to unseen situations where the object is not influenced by the actuator. Although the Abstract Collection Selector does know at least one \gls{ac} where only the actuator is moving, it is not able to learn the correct selection on the provided training samples.
Adding another training run, that passes the object on one side results in correct predictions for the testing runs on that side, but usually not on the other one.
%TODO add figure for that?
This generalization capability is due to the additional features of distance and closing in the object state concept. Without these two features, the object state concept performs similar to the interaction concept in these unknown cases.
However, simply adding equivalent features to the interaction model is not guaranteed to produce better results as it further increases the dimensionality of the feature vector and thus of the input space the regression model needs to learn. %TODO citation?

%It is interesting to note, that the object state model appears to be a lot more 	susceptible to the noise in the data since the standard deviations are a lot higher (up to twice as big) than in the interaction state model. It appears that the local forward model of the actuator, which is only trained on the action primitive and the positional change in the actuator, is the cause for this increased variability.
%TODO Not quite true anymore with the new sigma

\subsection{Generalization in the open loop} %TODO maybe rename. don't use open loop

The images in figure \ref{fig:pushTaskSim2} showcase the one-shot learning capabilities of the memory based regression and classification models. While the models lag one timestep behind in the first run, they successfully predict changes in the actuator correctly in the second run. 
The predictions for the block are already quite good in the first run because the model reaches the block in the predictions only after it was already updated by the actual interaction. While the rotations are predicted one frame later then in actual reality due to the late start for the actuator, the actual block predictions are accurate.

The interaction in the 2nd row is interesting. Since the actuator prediction is accurate, the model has never seen the interaction at this side before it comes to predicting it. Therefore, it predicts the rotation from the situation that is closest to the current situation. In this case, this results in the wrong rotation prediction.
Furthermore, an impossible configuration of actuator and block is predicted where the actuator is located within the block. The model does not know about physical laws and performs no checks for such situations.
In the next frames, the model adapts its forward model to the new information it is being provided and starts rotating the prediction in the other direction. The relatively big error cannot be corrected completely since the predicted actuator quickly reaches a position where the gating function does not predict any more influence on the predicted block. 

Nevertheless, the images show the one-shot capabilities one would expect from memory-based approaches. If a higher update rate is used, such as 100Hz as in the other experiments, smaller prediction errors will be made. In that case the currently predicted situation remains close to the actual situation, which means that the model can still apply what it has just learned for its next prediction.


\subsection{Extension two multiple objects}

The results in section \ref{sec:multipleObjects} show that the object state model can easily deal with multiple objects in the environment. While the interaction state model suffers from the decision problem between multiple alternative predictions as discussed in section \ref{sec:interactionTheory}, the object state model does not need to be adapted in order to successfully make predictions for different types of objects. 

However, the results in \ref{fig:eachPosTwoObjects} indicate a problem with gating function. More precisely with the \gls{aitm} when it is used for (binary) classification. The \gls{aitm} relies on the output error when deciding to add a new node. In the binary classification case, this output will always only be one of two values (0 or 1). The result of that is, that the first nodes that are inserted as prototypes for either case are used to cover a large input space. If not sufficient amounts of diverse training samples are seen, this will lead to poor performances. Ideally, the node deletion scheme would remove nodes far away from the decision border over time, but this does not seem to be the case in this scenario.

Unfortunately, the object state concept is not able to make predictions about object-object interactions. Although, the general idea for object-object interactions is explained in the concept's description (see section \ref{sec:gatePrediction}), the problem of determining the correct causal relation in order to train an appropriate gating function was not solved over the course of this thesis.

\section{Reaching target states}

The second task was designed in order to evaluate the learned inverse models of the concepts. Both concepts essentially use the same underlying inverse model, which was designed for the challenges that the incremental learning approach entails. 
For that reason, this section can also be understood as a discussion of the developed inverse model.

The inverse model itself is not provided with any domain knowledge, but does make the assumption about averaging feature dimensions. 
However, it was necessary to provide the models with information about what some feature dimensions represent in order to successfully reach a given target configuration. 
Furthermore, it was required to provide a circling action in order to avoid moving blocks arbitrarily.

Both models reach the target configuration most of the time. Target 1 appears to be more difficult for both models compared to the other targets. 
Looking at the test runs for Target 1 in more detail revealed that the \gls{tiim} often selected suboptimal preconditions in the cases, where the target was not, or just barely reached.
Two possible reasons for this poor performance come to mind:
\begin{enumerate}
\item The merging process produces suboptimal alternatives within the nodes.
\item The network selects the worse of two provided alternatives.
\end{enumerate}

1) Due to numerical inaccuracy as well as noise, some suboptimal combinations can become dominant within a prototype. In this case, the optimal combinations might be lost during the merging process. The likelihood for this is reduced by the stricter merging process described in section \ref{sec:invModelRealization}, but not completely removed.

2) The greedy strategy of the network compares the two alternative preconditions for the currently biggest feature dimension to the alternatives of the second biggest feature dimension. The alternative that is closest to either of the second alternatives is chosen. This decision was motivated by the idea of planning ahead for the next feature dimension in order to avoid unnecessary circling movements around the objects.

In case some of these alternative are suboptimal (e.g. due to the first problem), the network might choose a bad precondition, even if the other alternative would have been optimal. 
Furthermore, not all feature dimensions in the precondition should be considered when looking at closeness. For example, the preconditions for both models contain the relative actuator velocity (in the interaction model this is implicitly given in the included action primitive). 
Different interactions require different velocities in order to produce the desired changes in the object's state. 
However, since the velocity of the actuator can be changed directly, it should not be considered when trying to choose the precondition that is closest to the preconditions required for the next feature. Preprocessed features or a fine tuned distance metric for preconditions would certainly reduce this problem, but is not available in the given setting.

In some cases the network might even oscillate between two valid alternatives (e.g. for turning the object) which results in many circling actions around the object without actually moving it much.

Another thing to note is that the interaction concept generally requires more steps in order to reach the target than the object state concept. Careful analysis of the testing runs revealed that the used circling decision plays a big part in this. The decision, if the model should employ a circling action or not, depends on the distance to the location determined by the preconditions. In case the actuator simply needs to move to the other side of a corner, no circling action is employed but the actuator is moved directly in the direction towards the location. While the object state model uses the gating function in order to determine if this action is safe in the sense that it does not move the object, the interaction state model does not have such a feature. Therefore, the block is often moved in an undesired way which needs to be corrected by additional interactions.

Another problem concerning the used features without additional information was revealed by figure \ref{fig:moveToTargetInteractionT4Detail}: The orientation that is provided by the environment is in the range of $[-\pi,\pi]$ as is often done for angles. The model does not know that turning above $\pi$ results in negative orientations. It also does not know that the orientation $3.14$ and $-3.14$ are actually very close rather than far apart. Which is the reason why the interaction model did not realize that it had already reached the target in the situation of the figure. 

On the positive side, the proposed inverse model does not suffer from the general problem of memory based approaches that they become computational expensive the more training data they receive. This is because the inverse model stores only a nearly constant amount of values in order to compute the averages for each feature dimension. The number of possible sign combinations that are stored separately is limited by the size of the superset of sign combinations. Furthermore, the inverse model successfully allows to deduce action primitive suitable to reduce the distance to a given state. This is also true for distances far greater than anything the model has seen during training. In that sense, the proposed inverse model is capable of enormous extrapolation.

The inverse model does not provide an action plan to reach a given target. Actual action sequences would need to be planned by higher level components of the robot. 
However, the provided forward and inverse model should provide the required tools in order to formulate plans successfully.
In a sense, the models currently do that just that by analyzing the returned preconditions, defining intermediate targets for the actuator and computing a path (circling) in order to reach these intermediate targets without collision. Due to the interactive nature of this setting, the plans are never kept for more than a single update step but rather recomputed at every step in order to adapt to new situations.

\section{The Adapted Instantaneous Topological Mapping} %TODO Change name

Both developed implementations use the same underlying regression and classification model in the form of the \gls{aitm}. Being an adaptation of the \gls{gng} and similar in its output to a \gls{knn} it does suffer from the typical problem of memory based problems when it comes to unnormalized features. 

Nevertheless, combined with the proposed models it is able to make fairly accurate predictions about a complex environment without preprocessing any features or using special distance metrics. Furthermore, the method was also successfully used as a classifier in both the binary and the general case. Only the output interpolation needs to be turned off in order for the identical method to work for classification instead of regression. 

Both implementations do not really adapt the created nodes within the network, but rather rely on the topological mapping for the most part. The main reason for not using learning rates to adapt already learned nodes, is that the learning rates would need to be fine tuned to the given situation. Since the idea of this thesis is to develop and test models that adapt to unknown situations, reducing the number of tuned meta parameters is desired. In fact, having to choose the parameters listed in table \ref{tab:parameters} is already questionable.

Another reason for not using learning rates, especially for the matrix $A$ is that it can require a lot of training iterations before a stable matrix is found. In order not to influence early predictions, the matrix needs to be initialized as a zero matrix of suitable dimensions. Depending on the learning rate and the changes in the data, updating a zero matrix can easily lead to instabilities.
Since the models constantly rely on the regression method, it is better to use a constant output per node instead of adding noise through an incorrect linear interpolation. Especially, since the method already interpolates between the output of two nodes.
In scenarios where more training data and more prior knowledge is available the amount of required nodes is likely to decrease significantly when using positive learning rates.

\section{Concept comparison}

This thesis provides two different concepts in order to incrementally learn simple object manipulations. The main differences between the concepts are summarized in table \ref{tab:comparison}.

\begin{table}
	\footnotesize
	\centering
	\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} c c c}
			\hline  & \textbf{Pairwise interaction} & \textbf{Object state} \\
			\hline \hline 
			 World representation & Pairwise interaction states & Individual object states  \\ 
			 Actuator representation & Only part of an interaction state & Explicitly modeled \\
			 Action primitive & Influence any interaction state & Influences the actuator \\
			 Subspace creation & Changing feature sets & Object groups \\
			 Interaction separation & None & Gating function \\
			 Prediction & Simultaneously & Subsequently starting at actuator \\
			\hline 
	\end{tabular*} 
	\caption{Summary of the main differences of the two developed concepts.}
	\label{tab:comparison}
\end{table}

Both concepts use the same memory based regression and classification methods for the actual predictions and mainly differ in the way represent their environment. The pairwise interaction concept uses pairwise interaction states between two objects in order to represent both objects together. The object state with gating function concept on the other hand represents the objects individually and uses these to compute pairwise features when required.

Both concepts split the state space they encounter into local subspaces. While this is biologically inspired \cite{kawato1999internal}, the main reason was to reduce the burden on the trained regression models and allow for quicker update and query times.

The object state concept uses a gating function in order to differentiate between interactions that influence another object and those that do not. This greatly reduces the complexity of the local models for each object group. The findings Johansson et al. also provide some evidence for a similar concept in humans, by highlighting the importance of contact events \cite{johansson2001eye}. The predictions of the gating function can be interpreted as contact predictions in this context.

The object state concept is tailored more specifically to the given situation of object manipulation by explicitly representing the actuator. The interaction state concept on the other hand does not even know of different objects for prediction. This knowledge needs to be provided when trying to reach target states.

In that sense, the interaction state concept is better suited for the initial problem of automatically adapting to unknown environments because it makes less assumptions in its structure about the possible environments. 
However, the object state concept's assumption about separating the actuator explicitly might be reasonable in the context of robotics, where the robot should at least be provided with basic knowledge about itself. 



